<style> p,h1,h2,h3,h4,h5{ padding-left:10px; } </style>
<!DOCTYPE html><html><head><meta charset="utf-8"><title>README.md</title><style>@charset "UTF-8";@import 'https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-alpha2/katex.min.css';code{color:#c7254e;background-color:#f9f2f4;border-radius:4px}code,kbd{padding:2px 4px}kbd{color:#fff;background-color:#333;border-radius:3px;box-shadow:inset 0 -1px 0 rgba(0,0,0,.25)}kbd kbd{padding:0;font-size:100%;box-shadow:none}pre{display:block;margin:0 0 10px;word-break:break-all;word-wrap:break-word;color:#333;background-color:#f5f5f5;border:1px solid #ccc;border-radius:4px}pre code{padding:0;font-size:inherit;color:inherit;white-space:pre-wrap;background-color:transparent;border-radius:0}.pre-scrollable{max-height:340px;overflow-y:scroll}table{background-color:transparent}th{text-align:left}.table{width:100%;max-width:100%;margin-bottom:20px}.table>thead>tr>th{padding:8px;line-height:1.4285714;border-top:1px solid #ddd}.table>thead>tr>td,.table>tbody>tr>th,.table>tbody>tr>td,.table>tfoot>tr>th,.table>tfoot>tr>td{padding:8px;line-height:1.4285714;vertical-align:top;border-top:1px solid #ddd}.table>thead>tr>th{vertical-align:bottom;border-bottom:2px solid #ddd}.table>caption+thead>tr:first-child>th,.table>caption+thead>tr:first-child>td,.table>colgroup+thead>tr:first-child>th,.table>colgroup+thead>tr:first-child>td,.table>thead:first-child>tr:first-child>th,.table>thead:first-child>tr:first-child>td{border-top:0}.table>tbody+tbody{border-top:2px solid #ddd}.table .table{background-color:#fff}.table-condensed>thead>tr>th,.table-condensed>thead>tr>td,.table-condensed>tbody>tr>th,.table-condensed>tbody>tr>td,.table-condensed>tfoot>tr>th,.table-condensed>tfoot>tr>td{padding:5px}.table-bordered,.table-bordered>thead>tr>th,.table-bordered>thead>tr>td,.table-bordered>tbody>tr>th,.table-bordered>tbody>tr>td,.table-bordered>tfoot>tr>th,.table-bordered>tfoot>tr>td{border:1px solid #ddd}.table-bordered>thead>tr>th,.table-bordered>thead>tr>td{border-bottom-width:2px}.table-striped>tbody>tr:nth-child(odd)>td,.table-striped>tbody>tr:nth-child(odd)>th{background-color:#f9f9f9}.table-hover>tbody>tr:hover>td,.table-hover>tbody>tr:hover>th{background-color:#f5f5f5}table col[class*="col-"]{position:static;float:none;display:table-column}table td[class*="col-"],table th[class*="col-"]{position:static;float:none;display:table-cell}.table>thead>tr>td.active,.table>thead>tr>th.active,.table>thead>tr.active>td,.table>thead>tr.active>th,.table>tbody>tr>td.active,.table>tbody>tr>th.active,.table>tbody>tr.active>td,.table>tbody>tr.active>th,.table>tfoot>tr>td.active,.table>tfoot>tr>th.active,.table>tfoot>tr.active>td,.table>tfoot>tr.active>th{background-color:#f5f5f5}.table-hover>tbody>tr>td.active:hover,.table-hover>tbody>tr>th.active:hover,.table-hover>tbody>tr.active:hover>td,.table-hover>tbody>tr:hover>.active,.table-hover>tbody>tr.active:hover>th{background-color:#e8e8e8}.table>thead>tr>td.success,.table>thead>tr>th.success,.table>thead>tr.success>td,.table>thead>tr.success>th,.table>tbody>tr>td.success,.table>tbody>tr>th.success,.table>tbody>tr.success>td,.table>tbody>tr.success>th,.table>tfoot>tr>td.success,.table>tfoot>tr>th.success,.table>tfoot>tr.success>td,.table>tfoot>tr.success>th{background-color:#dff0d8}.table-hover>tbody>tr>td.success:hover,.table-hover>tbody>tr>th.success:hover,.table-hover>tbody>tr.success:hover>td,.table-hover>tbody>tr:hover>.success,.table-hover>tbody>tr.success:hover>th{background-color:#d0e9c6}.table>thead>tr>td.info,.table>thead>tr>th.info,.table>thead>tr.info>td,.table>thead>tr.info>th,.table>tbody>tr>td.info,.table>tbody>tr>th.info,.table>tbody>tr.info>td,.table>tbody>tr.info>th,.table>tfoot>tr>td.info,.table>tfoot>tr>th.info,.table>tfoot>tr.info>td,.table>tfoot>tr.info>th{background-color:#d9edf7}.table-hover>tbody>tr>td.info:hover,.table-hover>tbody>tr>th.info:hover,.table-hover>tbody>tr.info:hover>td,.table-hover>tbody>tr:hover>.info,.table-hover>tbody>tr.info:hover>th{background-color:#c4e3f3}.table>thead>tr>td.warning,.table>thead>tr>th.warning,.table>thead>tr.warning>td,.table>thead>tr.warning>th,.table>tbody>tr>td.warning,.table>tbody>tr>th.warning,.table>tbody>tr.warning>td,.table>tbody>tr.warning>th,.table>tfoot>tr>td.warning,.table>tfoot>tr>th.warning,.table>tfoot>tr.warning>td,.table>tfoot>tr.warning>th{background-color:#fcf8e3}.table-hover>tbody>tr>td.warning:hover,.table-hover>tbody>tr>th.warning:hover,.table-hover>tbody>tr.warning:hover>td,.table-hover>tbody>tr:hover>.warning,.table-hover>tbody>tr.warning:hover>th{background-color:#faf2cc}.table>thead>tr>td.danger,.table>thead>tr>th.danger,.table>thead>tr.danger>td,.table>thead>tr.danger>th,.table>tbody>tr>td.danger,.table>tbody>tr>th.danger,.table>tbody>tr.danger>td,.table>tbody>tr.danger>th,.table>tfoot>tr>td.danger,.table>tfoot>tr>th.danger,.table>tfoot>tr.danger>td,.table>tfoot>tr.danger>th{background-color:#f2dede}.table-hover>tbody>tr>td.danger:hover,.table-hover>tbody>tr>th.danger:hover,.table-hover>tbody>tr.danger:hover>td,.table-hover>tbody>tr:hover>.danger,.table-hover>tbody>tr.danger:hover>th{background-color:#ebcccc}fieldset{border:0;min-width:0}legend{display:block;width:100%;margin-bottom:20px;font-size:21px;line-height:inherit;color:#333;border-bottom:1px solid #e5e5e5}label{display:inline-block;max-width:100%;margin-bottom:5px;font-weight:700}input[type="radio"],input[type="checkbox"]{margin:4px 0 0;margin-top:1px \9;line-height:normal}input[type="file"]{display:block}input[type="range"]{display:block;width:100%}select[multiple],select[size]{height:auto}input[type="file"]:focus,input[type="radio"]:focus,input[type="checkbox"]:focus{outline:thin dotted;outline:5px auto -webkit-focus-ring-color;outline-offset:-2px}output{padding-top:7px}output,.form-control{display:block;font-size:14px;line-height:1.4285714;color:#555}.form-control{width:100%;height:34px;padding:6px 12px;background-color:#fff;background-image:none;border:1px solid #ccc;border-radius:4px;box-shadow:inset 0 1px 1px rgba(0,0,0,.075);-webkit-transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s;transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s}.form-control:focus{border-color:#66afe9;outline:0;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 8px rgba(102,175,233,.6)}.form-control::-moz-placeholder{color:#777;opacity:1}.form-control:-ms-input-placeholder{color:#777}.form-control::-webkit-input-placeholder{color:#777}.form-control[disabled],.form-control[readonly],fieldset[disabled] .form-control{cursor:not-allowed;background-color:#eee;opacity:1}textarea.form-control{height:auto}input[type="date"],input[type="time"],input[type="datetime-local"],input[type="month"]{line-height:34px;line-height:1.4285714 \0}input[type="date"].input-sm,.form-horizontal .form-group-sm input[type="date"].form-control,.input-group-sm>input[type="date"].form-control,.input-group-sm>input[type="date"].input-group-addon,.input-group-sm>.input-group-btn>input[type="date"].btn,input[type="time"].input-sm,.form-horizontal .form-group-sm input[type="time"].form-control,.input-group-sm>input[type="time"].form-control,.input-group-sm>input[type="time"].input-group-addon,.input-group-sm>.input-group-btn>input[type="time"].btn,input[type="datetime-local"].input-sm,.form-horizontal .form-group-sm input[type="datetime-local"].form-control,.input-group-sm>input[type="datetime-local"].form-control,.input-group-sm>input[type="datetime-local"].input-group-addon,.input-group-sm>.input-group-btn>input[type="datetime-local"].btn,input[type="month"].input-sm,.form-horizontal .form-group-sm input[type="month"].form-control,.input-group-sm>input[type="month"].form-control,.input-group-sm>input[type="month"].input-group-addon,.input-group-sm>.input-group-btn>input[type="month"].btn{line-height:30px}input[type="date"].input-lg,.form-horizontal .form-group-lg input[type="date"].form-control,.input-group-lg>input[type="date"].form-control,.input-group-lg>input[type="date"].input-group-addon,.input-group-lg>.input-group-btn>input[type="date"].btn,input[type="time"].input-lg,.form-horizontal .form-group-lg input[type="time"].form-control,.input-group-lg>input[type="time"].form-control,.input-group-lg>input[type="time"].input-group-addon,.input-group-lg>.input-group-btn>input[type="time"].btn,input[type="datetime-local"].input-lg,.form-horizontal .form-group-lg input[type="datetime-local"].form-control,.input-group-lg>input[type="datetime-local"].form-control,.input-group-lg>input[type="datetime-local"].input-group-addon,.input-group-lg>.input-group-btn>input[type="datetime-local"].btn,input[type="month"].input-lg,.form-horizontal .form-group-lg input[type="month"].form-control,.input-group-lg>input[type="month"].form-control,.input-group-lg>input[type="month"].input-group-addon,.input-group-lg>.input-group-btn>input[type="month"].btn{line-height:46px}.form-group{margin-bottom:15px}.radio,.checkbox{position:relative;display:block;min-height:20px;margin-top:10px;margin-bottom:10px}.radio label,.checkbox label{padding-left:20px;margin-bottom:0;font-weight:400;cursor:pointer}.radio input[type="radio"],.radio-inline input[type="radio"],.checkbox input[type="checkbox"],.checkbox-inline input[type="checkbox"]{position:absolute;margin-left:-20px;margin-top:4px \9}.radio+.radio,.checkbox+.checkbox{margin-top:-5px}.radio-inline,.checkbox-inline{display:inline-block;padding-left:20px;margin-bottom:0;vertical-align:middle;font-weight:400;cursor:pointer}.radio-inline+.radio-inline,.checkbox-inline+.checkbox-inline{margin-top:0;margin-left:10px}input[type="radio"][disabled],input[type="radio"].disabled,fieldset[disabled] input[type="radio"],input[type="checkbox"][disabled],input[type="checkbox"].disabled,fieldset[disabled] input[type="checkbox"],.radio-inline.disabled,fieldset[disabled] .radio-inline,.checkbox-inline.disabled,fieldset[disabled] .checkbox-inline,.radio.disabled label,fieldset[disabled] .radio label,.checkbox.disabled label,fieldset[disabled] .checkbox label{cursor:not-allowed}.form-control-static{padding-top:7px;padding-bottom:7px;margin-bottom:0}.form-control-static.input-lg,.form-horizontal .form-group-lg .form-control-static.form-control,.input-group-lg>.form-control-static.form-control,.input-group-lg>.form-control-static.input-group-addon,.input-group-lg>.input-group-btn>.form-control-static.btn,.form-control-static.input-sm,.form-horizontal .form-group-sm .form-control-static.form-control,.input-group-sm>.form-control-static.form-control,.input-group-sm>.form-control-static.input-group-addon,.input-group-sm>.input-group-btn>.form-control-static.btn{padding-left:0;padding-right:0}.input-sm,.form-horizontal .form-group-sm .form-control,.input-group-sm>.form-control{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:3px}.input-group-sm>.input-group-addon{height:30px;line-height:1.5}.input-group-sm>.input-group-btn>.btn{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:3px}select.input-sm,.form-horizontal .form-group-sm select.form-control,.input-group-sm>select.form-control,.input-group-sm>select.input-group-addon,.input-group-sm>.input-group-btn>select.btn{height:30px;line-height:30px}textarea.input-sm,.form-horizontal .form-group-sm textarea.form-control,.input-group-sm>textarea.form-control,.input-group-sm>textarea.input-group-addon,.input-group-sm>.input-group-btn>textarea.btn,select[multiple].input-sm,.form-horizontal .form-group-sm select[multiple].form-control,.input-group-sm>select[multiple].form-control,.input-group-sm>select[multiple].input-group-addon,.input-group-sm>.input-group-btn>select[multiple].btn{height:auto}.input-lg,.form-horizontal .form-group-lg .form-control,.input-group-lg>.form-control{height:46px;padding:10px 16px;font-size:18px;line-height:1.33;border-radius:6px}.input-group-lg>.input-group-addon{height:46px;line-height:1.33}.input-group-lg>.input-group-btn>.btn{height:46px;padding:10px 16px;font-size:18px;line-height:1.33;border-radius:6px}select.input-lg,.form-horizontal .form-group-lg select.form-control,.input-group-lg>select.form-control,.input-group-lg>select.input-group-addon,.input-group-lg>.input-group-btn>select.btn{height:46px;line-height:46px}textarea.input-lg,.form-horizontal .form-group-lg textarea.form-control,.input-group-lg>textarea.form-control,.input-group-lg>textarea.input-group-addon,.input-group-lg>.input-group-btn>textarea.btn,select[multiple].input-lg,.form-horizontal .form-group-lg select[multiple].form-control,.input-group-lg>select[multiple].form-control,.input-group-lg>select[multiple].input-group-addon,.input-group-lg>.input-group-btn>select[multiple].btn{height:auto}.has-feedback{position:relative}.has-feedback .form-control{padding-right:42.5px}.form-control-feedback{position:absolute;top:25px;right:0;z-index:2;display:block;width:34px;height:34px;line-height:34px;text-align:center}.input-lg+.form-control-feedback,.form-horizontal .form-group-lg .form-control+.form-control-feedback,.input-group-lg>.form-control+.form-control-feedback,.input-group-lg>.input-group-addon+.form-control-feedback,.input-group-lg>.input-group-btn>.btn+.form-control-feedback{width:46px;height:46px;line-height:46px}.input-sm+.form-control-feedback,.form-horizontal .form-group-sm .form-control+.form-control-feedback,.input-group-sm>.form-control+.form-control-feedback,.input-group-sm>.input-group-addon+.form-control-feedback,.input-group-sm>.input-group-btn>.btn+.form-control-feedback{width:30px;height:30px;line-height:30px}.has-success .help-block,.has-success .control-label,.has-success .radio,.has-success .checkbox,.has-success .radio-inline,.has-success .checkbox-inline{color:#3c763d}.has-success .form-control{border-color:#3c763d;box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.has-success .form-control:focus{border-color:#2b542c;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #67b168}.has-success .input-group-addon{color:#3c763d;border-color:#3c763d;background-color:#dff0d8}.has-success .form-control-feedback{color:#3c763d}.has-warning .help-block,.has-warning .control-label,.has-warning .radio,.has-warning .checkbox,.has-warning .radio-inline,.has-warning .checkbox-inline{color:#8a6d3b}.has-warning .form-control{border-color:#8a6d3b;box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.has-warning .form-control:focus{border-color:#66512c;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #c0a16b}.has-warning .input-group-addon{color:#8a6d3b;border-color:#8a6d3b;background-color:#fcf8e3}.has-warning .form-control-feedback{color:#8a6d3b}.has-error .help-block,.has-error .control-label,.has-error .radio,.has-error .checkbox,.has-error .radio-inline,.has-error .checkbox-inline{color:#a94442}.has-error .form-control{border-color:#a94442;box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.has-error .form-control:focus{border-color:#843534;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #ce8483}.has-error .input-group-addon{color:#a94442;border-color:#a94442;background-color:#f2dede}.has-error .form-control-feedback{color:#a94442}.has-feedback label.sr-only~.form-control-feedback{top:0}.help-block{display:block;margin-top:5px;margin-bottom:10px;color:#737373}.form-horizontal .radio,.form-horizontal .checkbox,.form-horizontal .radio-inline,.form-horizontal .checkbox-inline{margin-top:0;margin-bottom:0;padding-top:7px}.form-horizontal .radio,.form-horizontal .checkbox{min-height:27px}.form-horizontal .form-group{margin-left:-15px;margin-right:-15px}.form-horizontal .form-group:before{content:" ";display:table}.form-horizontal .form-group:after{content:" ";display:table;clear:both}.form-horizontal .has-feedback .form-control-feedback{top:0;right:15px}.btn{display:inline-block;vertical-align:middle;cursor:pointer;background-image:none;border:1px solid transparent;white-space:nowrap;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.btn:focus,.btn:active:focus,.btn.active:focus{outline:thin dotted;outline:5px auto -webkit-focus-ring-color;outline-offset:-2px}.btn:hover,.btn:focus{color:#333;text-decoration:none}.btn:active,.btn.active{outline:0;background-image:none;box-shadow:inset 0 3px 5px rgba(0,0,0,.125)}.btn.disabled,.btn[disabled],fieldset[disabled] .btn{cursor:not-allowed;pointer-events:none;opacity:.65;filter:alpha(opacity=65);box-shadow:none}.btn-default{color:#333;background-color:#fff;border-color:#ccc}.btn-default:hover,.btn-default:focus,.btn-default:active,.btn-default.active,.open>.btn-default.dropdown-toggle{color:#333;background-color:#e6e6e6;border-color:#adadad}.btn-default:active,.btn-default.active,.open>.btn-default.dropdown-toggle{background-image:none}.btn-default.disabled,.btn-default.disabled:hover,.btn-default.disabled:focus,.btn-default.disabled:active,.btn-default.disabled.active,.btn-default[disabled],.btn-default[disabled]:hover,.btn-default[disabled]:focus,.btn-default[disabled]:active,.btn-default[disabled].active,fieldset[disabled] .btn-default,fieldset[disabled] .btn-default:hover,fieldset[disabled] .btn-default:focus,fieldset[disabled] .btn-default:active,fieldset[disabled] .btn-default.active{background-color:#fff;border-color:#ccc}.btn-default .badge{color:#fff;background-color:#333}.btn-primary{color:#fff;background-color:#428bca;border-color:#357ebd}.btn-primary:hover,.btn-primary:focus,.btn-primary:active,.btn-primary.active,.open>.btn-primary.dropdown-toggle{color:#fff;background-color:#3071a9;border-color:#285e8e}.btn-primary:active,.btn-primary.active,.open>.btn-primary.dropdown-toggle{background-image:none}.btn-primary.disabled,.btn-primary.disabled:hover,.btn-primary.disabled:focus,.btn-primary.disabled:active,.btn-primary.disabled.active,.btn-primary[disabled],.btn-primary[disabled]:hover,.btn-primary[disabled]:focus,.btn-primary[disabled]:active,.btn-primary[disabled].active,fieldset[disabled] .btn-primary,fieldset[disabled] .btn-primary:hover,fieldset[disabled] .btn-primary:focus,fieldset[disabled] .btn-primary:active,fieldset[disabled] .btn-primary.active{background-color:#428bca;border-color:#357ebd}.btn-primary .badge{color:#428bca;background-color:#fff}.btn-success{color:#fff;background-color:#5cb85c;border-color:#4cae4c}.btn-success:hover,.btn-success:focus,.btn-success:active,.btn-success.active,.open>.btn-success.dropdown-toggle{color:#fff;background-color:#449d44;border-color:#398439}.btn-success:active,.btn-success.active,.open>.btn-success.dropdown-toggle{background-image:none}.btn-success.disabled,.btn-success.disabled:hover,.btn-success.disabled:focus,.btn-success.disabled:active,.btn-success.disabled.active,.btn-success[disabled],.btn-success[disabled]:hover,.btn-success[disabled]:focus,.btn-success[disabled]:active,.btn-success[disabled].active,fieldset[disabled] .btn-success,fieldset[disabled] .btn-success:hover,fieldset[disabled] .btn-success:focus,fieldset[disabled] .btn-success:active,fieldset[disabled] .btn-success.active{background-color:#5cb85c;border-color:#4cae4c}.btn-success .badge{color:#5cb85c;background-color:#fff}.btn-info{color:#fff;background-color:#5bc0de;border-color:#46b8da}.btn-info:hover,.btn-info:focus,.btn-info:active,.btn-info.active,.open>.btn-info.dropdown-toggle{color:#fff;background-color:#31b0d5;border-color:#269abc}.btn-info:active,.btn-info.active,.open>.btn-info.dropdown-toggle{background-image:none}.btn-info.disabled,.btn-info.disabled:hover,.btn-info.disabled:focus,.btn-info.disabled:active,.btn-info.disabled.active,.btn-info[disabled],.btn-info[disabled]:hover,.btn-info[disabled]:focus,.btn-info[disabled]:active,.btn-info[disabled].active,fieldset[disabled] .btn-info,fieldset[disabled] .btn-info:hover,fieldset[disabled] .btn-info:focus,fieldset[disabled] .btn-info:active,fieldset[disabled] .btn-info.active{background-color:#5bc0de;border-color:#46b8da}.btn-info .badge{color:#5bc0de;background-color:#fff}.btn-warning{color:#fff;background-color:#f0ad4e;border-color:#eea236}.btn-warning:hover,.btn-warning:focus,.btn-warning:active,.btn-warning.active,.open>.btn-warning.dropdown-toggle{color:#fff;background-color:#ec971f;border-color:#d58512}.btn-warning:active,.btn-warning.active,.open>.btn-warning.dropdown-toggle{background-image:none}.btn-warning.disabled,.btn-warning.disabled:hover,.btn-warning.disabled:focus,.btn-warning.disabled:active,.btn-warning.disabled.active,.btn-warning[disabled],.btn-warning[disabled]:hover,.btn-warning[disabled]:focus,.btn-warning[disabled]:active,.btn-warning[disabled].active,fieldset[disabled] .btn-warning,fieldset[disabled] .btn-warning:hover,fieldset[disabled] .btn-warning:focus,fieldset[disabled] .btn-warning:active,fieldset[disabled] .btn-warning.active{background-color:#f0ad4e;border-color:#eea236}.btn-warning .badge{color:#f0ad4e;background-color:#fff}.btn-danger{color:#fff;background-color:#d9534f;border-color:#d43f3a}.btn-danger:hover,.btn-danger:focus,.btn-danger:active,.btn-danger.active,.open>.btn-danger.dropdown-toggle{color:#fff;background-color:#c9302c;border-color:#ac2925}.btn-danger:active,.btn-danger.active,.open>.btn-danger.dropdown-toggle{background-image:none}.btn-danger.disabled,.btn-danger.disabled:hover,.btn-danger.disabled:focus,.btn-danger.disabled:active,.btn-danger.disabled.active,.btn-danger[disabled],.btn-danger[disabled]:hover,.btn-danger[disabled]:focus,.btn-danger[disabled]:active,.btn-danger[disabled].active,fieldset[disabled] .btn-danger,fieldset[disabled] .btn-danger:hover,fieldset[disabled] .btn-danger:focus,fieldset[disabled] .btn-danger:active,fieldset[disabled] .btn-danger.active{background-color:#d9534f;border-color:#d43f3a}.btn-danger .badge{color:#d9534f;background-color:#fff}.btn-link{color:#428bca;font-weight:400;cursor:pointer;border-radius:0}.btn-link,.btn-link:active,.btn-link[disabled],fieldset[disabled] .btn-link{background-color:transparent;box-shadow:none}.btn-link,.btn-link:hover,.btn-link:focus,.btn-link:active{border-color:transparent}.btn-link:hover,.btn-link:focus{color:#2a6496;text-decoration:underline;background-color:transparent}.btn-link[disabled]:hover,.btn-link[disabled]:focus,fieldset[disabled] .btn-link:hover,fieldset[disabled] .btn-link:focus{color:#777;text-decoration:none}.btn-lg{padding:10px 16px;font-size:18px;line-height:1.33;border-radius:6px}.btn-sm{padding:5px 10px}.btn-sm,.btn-xs{font-size:12px;line-height:1.5;border-radius:3px}.btn-xs{padding:1px 5px}.btn-block{display:block;width:100%}.btn-block+.btn-block{margin-top:5px}input[type="submit"].btn-block,input[type="reset"].btn-block,input[type="button"].btn-block{width:100%}.fade{opacity:0;-webkit-transition:opacity .15s linear;transition:opacity .15s linear}.fade.in{opacity:1}.collapse{display:none}.collapse.in{display:block}tr.collapse.in{display:table-row}tbody.collapse.in{display:table-row-group}.collapsing{position:relative;height:0;overflow:hidden;-webkit-transition:height .35s ease;transition:height .35s ease}.input-group{position:relative;display:table;border-collapse:separate}.input-group[class*="col-"]{float:none;padding-left:0;padding-right:0}.input-group .form-control{position:relative;z-index:2;float:left;width:100%;margin-bottom:0}.input-group-addon,.input-group-btn,.input-group .form-control{display:table-cell}.input-group-addon:not(:first-child):not(:last-child),.input-group-btn:not(:first-child):not(:last-child),.input-group .form-control:not(:first-child):not(:last-child){border-radius:0}.input-group-addon{white-space:nowrap}.input-group-addon,.input-group-btn{width:1%;vertical-align:middle}.input-group-addon{padding:6px 12px;font-size:14px;font-weight:400;line-height:1;color:#555;text-align:center;background-color:#eee;border:1px solid #ccc;border-radius:4px}.input-group-addon.input-sm,.form-horizontal .form-group-sm .input-group-addon.form-control,.input-group-sm>.input-group-addon,.input-group-sm>.input-group-btn>.input-group-addon.btn{padding:5px 10px;font-size:12px;border-radius:3px}.input-group-addon.input-lg,.form-horizontal .form-group-lg .input-group-addon.form-control,.input-group-lg>.input-group-addon,.input-group-lg>.input-group-btn>.input-group-addon.btn{padding:10px 16px;font-size:18px;border-radius:6px}.input-group-addon input[type="radio"],.input-group-addon input[type="checkbox"]{margin-top:0}.input-group .form-control:first-child,.input-group-addon:first-child,.input-group-btn:first-child>.btn,.input-group-btn:first-child>.btn-group>.btn,.input-group-btn:first-child>.dropdown-toggle,.input-group-btn:last-child>.btn:not(:last-child):not(.dropdown-toggle),.input-group-btn:last-child>.btn-group:not(:last-child)>.btn{border-bottom-right-radius:0;border-top-right-radius:0}.input-group-addon:first-child{border-right:0}.input-group .form-control:last-child,.input-group-addon:last-child,.input-group-btn:last-child>.btn,.input-group-btn:last-child>.btn-group>.btn,.input-group-btn:last-child>.dropdown-toggle,.input-group-btn:first-child>.btn:not(:first-child),.input-group-btn:first-child>.btn-group:not(:first-child)>.btn{border-bottom-left-radius:0;border-top-left-radius:0}.input-group-addon:last-child{border-left:0}.input-group-btn{font-size:0;white-space:nowrap}.input-group-btn,.input-group-btn>.btn{position:relative}.input-group-btn>.btn+.btn{margin-left:-1px}.input-group-btn>.btn:hover,.input-group-btn>.btn:focus,.input-group-btn>.btn:active{z-index:2}.input-group-btn:first-child>.btn,.input-group-btn:first-child>.btn-group{margin-right:-1px}.input-group-btn:last-child>.btn,.input-group-btn:last-child>.btn-group{margin-left:-1px}.pagination{display:inline-block;padding-left:0;margin:20px 0;border-radius:4px}.pagination>li{display:inline}.pagination>li>a,.pagination>li>span{position:relative;float:left;padding:6px 12px;line-height:1.4285714;text-decoration:none;color:#428bca;background-color:#fff;border:1px solid #ddd;margin-left:-1px}.pagination>li:first-child>a,.pagination>li:first-child>span{margin-left:0;border-bottom-left-radius:4px;border-top-left-radius:4px}.pagination>li:last-child>a,.pagination>li:last-child>span{border-bottom-right-radius:4px;border-top-right-radius:4px}.pagination>li>a:hover,.pagination>li>a:focus,.pagination>li>span:hover,.pagination>li>span:focus{color:#2a6496;background-color:#eee;border-color:#ddd}.pagination>.active>a,.pagination>.active>a:hover,.pagination>.active>a:focus,.pagination>.active>span,.pagination>.active>span:hover,.pagination>.active>span:focus{z-index:2;color:#fff;background-color:#428bca;border-color:#428bca;cursor:default}.pagination>.disabled>span,.pagination>.disabled>span:hover,.pagination>.disabled>span:focus,.pagination>.disabled>a,.pagination>.disabled>a:hover,.pagination>.disabled>a:focus{color:#777;background-color:#fff;border-color:#ddd;cursor:not-allowed}.pagination-lg>li>a,.pagination-lg>li>span{padding:10px 16px;font-size:18px}.pagination-lg>li:first-child>a,.pagination-lg>li:first-child>span{border-bottom-left-radius:6px;border-top-left-radius:6px}.pagination-lg>li:last-child>a,.pagination-lg>li:last-child>span{border-bottom-right-radius:6px;border-top-right-radius:6px}.pagination-sm>li>a,.pagination-sm>li>span{padding:5px 10px;font-size:12px}.pagination-sm>li:first-child>a,.pagination-sm>li:first-child>span{border-bottom-left-radius:3px;border-top-left-radius:3px}.pagination-sm>li:last-child>a,.pagination-sm>li:last-child>span{border-bottom-right-radius:3px;border-top-right-radius:3px}.close{float:right;font-size:21px;font-weight:700;line-height:1;color:#000;text-shadow:0 1px 0 #fff;opacity:.2;filter:alpha(opacity=20)}.close:hover,.close:focus{color:#000;text-decoration:none;cursor:pointer;opacity:.5;filter:alpha(opacity=50)}button.close{padding:0;cursor:pointer;background:0 0;border:0;-webkit-appearance:none}.modal-open,.modal{overflow:hidden}.modal{display:none;position:fixed;top:0;right:0;bottom:0;left:0;z-index:1050;-webkit-overflow-scrolling:touch;outline:0}.modal.fade .modal-dialog{-webkit-transform:translate3d(0,-25%,0);transform:translate3d(0,-25%,0);-webkit-transition:-webkit-transform .3s ease-out;transition:transform .3s ease-out;transition:transform .3s ease-out,-webkit-transform .3s ease-out}.modal.in .modal-dialog{-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}.modal-open .modal{overflow-x:hidden;overflow-y:auto}.modal-dialog{position:relative;width:auto;margin:10px}.modal-content{position:relative;background-color:#fff;border:1px solid #999;border:1px solid rgba(0,0,0,.2);border-radius:6px;box-shadow:0 3px 9px rgba(0,0,0,.5);background-clip:padding-box;outline:0}.modal-backdrop{position:fixed;top:0;right:0;bottom:0;left:0;z-index:1040;background-color:#000}.modal-backdrop.fade{opacity:0;filter:alpha(opacity=0)}.modal-backdrop.in{opacity:.5;filter:alpha(opacity=50)}.modal-header{padding:15px;border-bottom:1px solid #e5e5e5;min-height:16.4285714px}.modal-header .close{margin-top:-2px}.modal-title{margin:0;line-height:1.4285714}.modal-body{position:relative;padding:15px}.modal-footer{padding:15px;text-align:right;border-top:1px solid #e5e5e5}.modal-footer:before,.modal-footer:after{content:" ";display:table}.modal-footer:after{clear:both}.modal-footer .btn+.btn{margin-left:5px;margin-bottom:0}.modal-footer .btn-group .btn+.btn{margin-left:-1px}.modal-footer .btn-block+.btn-block{margin-left:0}.modal-scrollbar-measure{position:absolute;top:-9999px;width:50px;height:50px;overflow:scroll}.clearfix:before,.clearfix:after{content:" ";display:table}.clearfix:after{clear:both}.center-block{display:block;margin-left:auto;margin-right:auto}.pull-right{float:right!important}.pull-left{float:left!important}.hide{display:none!important}.show{display:block!important}.invisible{visibility:hidden}.text-hide{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;border:0}.hidden{display:none!important;visibility:hidden!important}.affix{position:fixed;-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}.hljs{display:block;overflow-x:auto;padding:.5em;background:#002b36;color:#839496;-webkit-text-size-adjust:none}.hljs-comment,.hljs-template_comment,.diff .hljs-header,.hljs-doctype,.hljs-pi,.lisp .hljs-string,.hljs-javadoc{color:#586e75}.hljs-keyword,.hljs-winutils,.method,.hljs-addition,.css .hljs-tag,.hljs-request,.hljs-status,.nginx .hljs-title{color:#859900}.hljs-number,.hljs-command,.hljs-string,.hljs-tag .hljs-value,.hljs-rules .hljs-value,.hljs-phpdoc,.hljs-dartdoc,.tex .hljs-formula,.hljs-regexp,.hljs-hexcolor,.hljs-link_url{color:#2aa198}.hljs-title,.hljs-localvars,.hljs-chunk,.hljs-decorator,.hljs-built_in,.hljs-identifier,.vhdl .hljs-literal,.hljs-id,.css .hljs-function{color:#268bd2}.hljs-attribute,.hljs-variable,.lisp .hljs-body,.smalltalk .hljs-number,.hljs-constant,.hljs-class .hljs-title,.hljs-parent,.hljs-type,.hljs-link_reference{color:#b58900}.hljs-preprocessor,.hljs-preprocessor .hljs-keyword,.hljs-pragma,.hljs-shebang,.hljs-symbol,.hljs-symbol .hljs-string,.diff .hljs-change,.hljs-special,.hljs-attr_selector,.hljs-subst,.hljs-cdata,.css .hljs-pseudo,.hljs-header{color:#cb4b16}.hljs-deletion,.hljs-important{color:#dc322f}.hljs-link_label{color:#6c71c4}.tex .hljs-formula{background:#073642}*,*:before,*:after{box-sizing:border-box}html{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background:0 0}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:700}dfn{font-style:italic}h1{margin:.67em 0}mark{background:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sup{top:-.5em}sub{bottom:-.25em}images{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{box-sizing:content-box;height:0}pre{overflow:auto}code,kbd{font-size:1em}code,kbd,pre,samp{font-family:monospace,monospace}samp{font-size:1em}button,input,optgroup,select,textarea{color:inherit;font:inherit;margin:0}button{overflow:visible}button,select{text-transform:none}button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}input{line-height:normal}input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}input[type="number"]::-webkit-inner-spin-button,input[type="number"]::-webkit-outer-spin-button{height:auto}input[type="search"]{-webkit-appearance:textfield;box-sizing:content-box}input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{border:0;padding:0}textarea{overflow:auto}optgroup{font-weight:700}table{border-collapse:collapse;border-spacing:0}.debug{background-color:#ffc0cb!important}.ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.ir{background-color:transparent;border:0;overflow:hidden}.ir::before{content:'';display:block;height:150%;width:0}html{font-size:.875em;background:#fff;color:#373D49}html,body{font-family:Georgia,Cambria,serif;height:100%}body{font-size:1rem;font-weight:400;line-height:2rem;overflow:hidden}ul,ol{margin-bottom:.83999rem;padding-top:.16001rem}li{-webkit-font-feature-settings:'kern' 1,'onum' 1,'liga' 1;font-feature-settings:'kern' 1,'onum' 1,'liga' 1;margin-left:1rem}li>ul,li>ol{margin-bottom:0}p{padding-top:.66001rem;-webkit-font-feature-settings:'kern' 1,'onum' 1,'liga' 1;font-feature-settings:'kern' 1,'onum' 1,'liga' 1;margin-top:0}p,pre{margin-bottom:1.33999rem}pre{font-size:1rem;padding:.66001rem 9.5px 9.5px;line-height:2rem;background:-webkit-linear-gradient(top,#fff 0,#fff .75rem,#f5f7fa .75rem,#f5f7fa 2.75rem,#fff 2.75rem,#fff 4rem);background:linear-gradient(to bottom,#fff 0,#fff .75rem,#f5f7fa .75rem,#f5f7fa 2.75rem,#fff 2.75rem,#fff 4rem);background-size:100% 4rem;border-color:#D3DAEA}blockquote{margin:0}blockquote p{font-size:1rem;margin-bottom:.33999rem;font-style:italic;padding:.66001rem 1rem 1rem;border-left:3px solid #A0AABF}th,td{padding:12px}h1,h2,h3,h4,h5,h6{font-family:"Source Sans Pro","Helvetica Neue",Helvetica,Arial,sans-serif;-webkit-font-feature-settings:'dlig' 1,'liga' 1,'lnum' 1,'kern' 1;font-feature-settings:'dlig' 1,'liga' 1,'lnum' 1,'kern' 1;font-style:normal;font-weight:600;margin-top:0}h1{line-height:3rem;font-size:2.0571429rem;margin-bottom:.21999rem;padding-top:.78001rem}h2{font-size:1.953125rem;margin-bottom:.1835837rem;padding-top:.8164163rem}h2,h3{line-height:3rem}h3{font-size:1.6457143rem;margin-bottom:.07599rem;padding-top:.92401rem}h4{font-size:1.5625rem;margin-bottom:.546865rem;padding-top:.453135rem}h5{font-size:1.25rem;margin-bottom:-.56251rem;padding-top:.56251rem}h6{font-size:1rem;margin-bottom:-.65001rem;padding-top:.65001rem}a{cursor:pointer;color:#35D7BB;text-decoration:none}a:hover,a:focus{border-bottom-color:#35D7BB;color:#dff9f4}img{height:auto;max-width:100%}.g{display:block}.g:after{clear:both;content:'';display:table}.g-b{float:left;margin:0;width:100%}.g{margin-left:-16px;margin-right:-16px}.g-b{padding-left:16px;padding-right:16px}.g-b--center{display:block;float:none;margin:0 auto}.g-b--right{float:right}.g-b--1of1{width:100%}.g-b--1of2,.g-b--2of4,.g-b--3of6,.g-b--4of8,.g-b--5of10,.g-b--6of12{width:50%}.g-b--1of3,.g-b--2of6,.g-b--4of12{width:33.333%}.g-b--2of3,.g-b--4of6,.g-b--8of12{width:66.666%}.g-b--1of4,.g-b--2of8,.g-b--3of12{width:25%}.g-b--3of4,.g-b--6of8,.g-b--9of12{width:75%}.g-b--1of5,.g-b--2of10{width:20%}.g-b--2of5,.g-b--4of10{width:40%}.g-b--3of5,.g-b--6of10{width:60%}.g-b--4of5,.g-b--8of10{width:80%}.g-b--1of6,.g-b--2of12{width:16.666%}.g-b--5of6,.g-b--10of12{width:83.333%}.g-b--1of8{width:12.5%}.g-b--3of8{width:37.5%}.g-b--5of8{width:62.5%}.g-b--7of8{width:87.5%}.g-b--1of10{width:10%}.g-b--3of10{width:30%}.g-b--7of10{width:70%}.g-b--9of10{width:90%}.g-b--1of12{width:8.333%}.g-b--5of12{width:41.666%}.g-b--7of12{width:58.333%}.g-b--11of12{width:91.666%}.g-b--push--1of1{margin-left:100%}.g-b--push--1of2,.g-b--push--2of4,.g-b--push--3of6,.g-b--push--4of8,.g-b--push--5of10,.g-b--push--6of12{margin-left:50%}.g-b--push--1of3,.g-b--push--2of6,.g-b--push--4of12{margin-left:33.333%}.g-b--push--2of3,.g-b--push--4of6,.g-b--push--8of12{margin-left:66.666%}.g-b--push--1of4,.g-b--push--2of8,.g-b--push--3of12{margin-left:25%}.g-b--push--3of4,.g-b--push--6of8,.g-b--push--9of12{margin-left:75%}.g-b--push--1of5,.g-b--push--2of10{margin-left:20%}.g-b--push--2of5,.g-b--push--4of10{margin-left:40%}.g-b--push--3of5,.g-b--push--6of10{margin-left:60%}.g-b--push--4of5,.g-b--push--8of10{margin-left:80%}.g-b--push--1of6,.g-b--push--2of12{margin-left:16.666%}.g-b--push--5of6,.g-b--push--10of12{margin-left:83.333%}.g-b--push--1of8{margin-left:12.5%}.g-b--push--3of8{margin-left:37.5%}.g-b--push--5of8{margin-left:62.5%}.g-b--push--7of8{margin-left:87.5%}.g-b--push--1of10{margin-left:10%}.g-b--push--3of10{margin-left:30%}.g-b--push--7of10{margin-left:70%}.g-b--push--9of10{margin-left:90%}.g-b--push--1of12{margin-left:8.333%}.g-b--push--5of12{margin-left:41.666%}.g-b--push--7of12{margin-left:58.333%}.g-b--push--11of12{margin-left:91.666%}.g-b--pull--1of1{margin-right:100%}.g-b--pull--1of2,.g-b--pull--2of4,.g-b--pull--3of6,.g-b--pull--4of8,.g-b--pull--5of10,.g-b--pull--6of12{margin-right:50%}.g-b--pull--1of3,.g-b--pull--2of6,.g-b--pull--4of12{margin-right:33.333%}.g-b--pull--2of3,.g-b--pull--4of6,.g-b--pull--8of12{margin-right:66.666%}.g-b--pull--1of4,.g-b--pull--2of8,.g-b--pull--3of12{margin-right:25%}.g-b--pull--3of4,.g-b--pull--6of8,.g-b--pull--9of12{margin-right:75%}.g-b--pull--1of5,.g-b--pull--2of10{margin-right:20%}.g-b--pull--2of5,.g-b--pull--4of10{margin-right:40%}.g-b--pull--3of5,.g-b--pull--6of10{margin-right:60%}.g-b--pull--4of5,.g-b--pull--8of10{margin-right:80%}.g-b--pull--1of6,.g-b--pull--2of12{margin-right:16.666%}.g-b--pull--5of6,.g-b--pull--10of12{margin-right:83.333%}.g-b--pull--1of8{margin-right:12.5%}.g-b--pull--3of8{margin-right:37.5%}.g-b--pull--5of8{margin-right:62.5%}.g-b--pull--7of8{margin-right:87.5%}.g-b--pull--1of10{margin-right:10%}.g-b--pull--3of10{margin-right:30%}.g-b--pull--7of10{margin-right:70%}.g-b--pull--9of10{margin-right:90%}.g-b--pull--1of12{margin-right:8.333%}.g-b--pull--5of12{margin-right:41.666%}.g-b--pull--7of12{margin-right:58.333%}.g-b--pull--11of12{margin-right:91.666%}.splashscreen{position:fixed;top:0;left:0;width:100%;height:100%;background-color:#373D49;z-index:22}.splashscreen-dillinger{width:260px;height:auto;display:block;margin:0 auto;padding-bottom:3rem}.splashscreen p{font-size:1.25rem;padding-top:.56251rem;font-family:"Source Sans Pro","Helvetica Neue",Helvetica,Arial,sans-serif;font-weight:400;text-align:center;max-width:500px;margin:0 auto;color:#FFF}.sp-center{position:relative;-webkit-transform:translateY(-50%);transform:translateY(-50%);top:50%}.open-menu>.wrapper{overflow-x:hidden}.page{margin:0 auto;position:relative;top:0;left:0;width:100%;height:100%;z-index:2;-webkit-transition:all .25s ease-in-out;transition:all .25s ease-in-out;background-color:#fff;padding-top:51px;will-change:left}.open-menu .page{left:270px}.title{line-height:1rem;font-size:.8rem;margin-bottom:.77999rem;padding-top:.22001rem;font-weight:500;color:#A0AABF;letter-spacing:1px;text-transform:uppercase;padding-left:16px;padding-right:16px;margin-top:1rem}.split-preview .title{padding-left:0}.title-document{line-height:1rem;font-size:1.25rem;margin-bottom:.89999rem;padding-top:.10001rem;font-weight:400;font-family:"Ubuntu Mono",Monaco;color:#373D49;padding-left:16px;padding-right:16px;width:80%;min-width:300px;outline:0;border:none}.icon{display:block;margin:0 auto;width:36px;height:36px;border-radius:3px;text-align:center}.icon svg{display:inline-block;margin-left:auto;margin-right:auto}.icon-preview{background-color:#373D49;line-height:40px}.icon-preview svg{width:19px;height:12px}.icon-settings{background-color:#373D49;line-height:44px}.icon-settings svg{width:18px;height:18px}.icon-link{width:16px;height:16px;line-height:1;margin-right:24px;text-align:right}.navbar{background-color:#373D49;height:51px;width:100%;position:fixed;top:0;left:0;z-index:6;-webkit-transition:all .25s ease-in-out;transition:all .25s ease-in-out;will-change:left}.navbar:after{content:"";display:table;clear:both}.open-menu .navbar{left:270px}.navbar-brand{float:left;margin:0 0 0 24px;padding:0;line-height:42px}.navbar-brand svg{width:85px;height:11px}.nav-left{float:left}.nav-right{float:right}.nav-sidebar{width:100%}.menu{list-style:none;margin:0;padding:0}.menu a{border:0;color:#A0AABF;font-family:"Source Sans Pro","Helvetica Neue",Helvetica,Arial,sans-serif;outline:none;text-transform:uppercase}.menu a:hover{color:#35D7BB}.menu .menu-item{border:0;display:none;float:left;margin:0;position:relative}.menu .menu-item>a{display:block;font-size:12px;height:51px;letter-spacing:1px;line-height:51px;padding:0 24px}.menu .menu-item--settings,.menu .menu-item--preview,.menu .menu-item--save-to.in-sidebar,.menu .menu-item--import-from.in-sidebar,.menu .menu-item--link-unlink.in-sidebar,.menu .menu-item--documents.in-sidebar{display:block}.menu .menu-item--documents{padding-bottom:1rem}.menu .menu-item.open>a{background-color:#1D212A}.menu .menu-item-icon>a{height:auto;padding:0}.menu .menu-item-icon:hover>a{background-color:transparent}.menu .menu-link.open i{background-color:#1D212A}.menu .menu-link.open g{fill:#35D7BB}.menu .menu-link-preview,.menu .menu-link-settings{margin-top:8px;width:51px}.menu-sidebar{width:100%}.menu-sidebar .menu-item{float:none;margin-bottom:1px;width:100%}.menu-sidebar .menu-item.open>a{background-color:#373D49}.menu-sidebar .open .caret{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.menu-sidebar>.menu-item:hover .dropdown a,.menu-sidebar>.menu-item:hover .settings a{background-color:transparent}.menu-sidebar .menu-link{background-color:#373D49;font-weight:600}.menu-sidebar .menu-link:after{content:"";display:table;clear:both}.menu-sidebar .menu-link>span{float:left}.menu-sidebar .menu-link>.caret{float:right;text-align:right;top:22px}.menu-sidebar .dropdown,.menu-sidebar .settings{background-color:transparent;position:static;width:100%}.dropdown{position:absolute;right:0;top:51px;width:188px}.dropdown,.settings{display:none;background-color:#1D212A}.dropdown{padding:0}.dropdown,.settings,.sidebar-list{list-style:none;margin:0}.sidebar-list{padding:0}.dropdown li{margin:32px 0;padding:0 0 0 32px}.dropdown li,.settings li{line-height:1}.sidebar-list li{line-height:1;margin:32px 0;padding:0 0 0 32px}.dropdown a{color:#D0D6E2}.dropdown a,.settings a,.sidebar-list a{display:block;text-transform:none}.sidebar-list a{color:#D0D6E2}.dropdown a:after,.settings a:after,.sidebar-list a:after{content:"";display:table;clear:both}.dropdown .icon,.settings .icon,.sidebar-list .icon{float:right}.open .dropdown,.open .settings,.open .sidebar-list{display:block}.open .dropdown.collapse,.open .collapse.settings,.open .sidebar-list.collapse{display:none}.open .dropdown.collapse.in,.open .collapse.in.settings,.open .sidebar-list.collapse.in{display:block}.dropdown .unlinked .icon,.settings .unlinked .icon,.sidebar-list .unlinked .icon{opacity:.3}.dropdown.documents li,.documents.settings li,.sidebar-list.documents li{background-image:url("../img/icons/file.svg");background-position:240px center;background-repeat:no-repeat;background-size:14px 16px;padding:3px 32px}.dropdown.documents li.octocat,.documents.settings li.octocat,.sidebar-list.documents li.octocat{background-image:url("../img/icons/octocat.svg");background-position:234px center;background-size:24px 24px}.dropdown.documents li:last-child,.documents.settings li:last-child,.sidebar-list.documents li:last-child{margin-bottom:1rem}.dropdown.documents li.active a,.documents.settings li.active a,.sidebar-list.documents li.active a{color:#35D7BB}.settings{position:fixed;top:67px;right:16px;border-radius:3px;width:288px;background-color:#373D49;padding:16px;z-index:7}.show-settings .settings{display:block}.settings .has-checkbox{float:left}.settings a{font-size:1.25rem;font-family:"Source Sans Pro","Helvetica Neue",Helvetica,Arial,sans-serif;font-weight:400;-webkit-font-smoothing:antialiased;line-height:28px;color:#D0D6E2}.settings a:after{content:"";display:table;clear:both}.settings a:hover{color:#35D7BB}.settings li{border-bottom:1px solid #4F535B;margin:0;padding:16px 0}.settings li:last-child{border-bottom:none}.brand{border:none;display:block}.brand:hover g{fill:#35D7BB}.toggle{display:block;float:left;height:16px;padding:25px 16px 26px;width:40px}.toggle span:after,.toggle span:before{content:'';left:0;position:absolute;top:-6px}.toggle span:after{top:6px}.toggle span{display:block;position:relative}.toggle span,.toggle span:after,.toggle span:before{-webkit-backface-visibility:hidden;backface-visibility:hidden;background-color:#D3DAEA;height:2px;-webkit-transition:all .3s;transition:all .3s;width:20px}.open-menu .toggle span{background-color:transparent}.open-menu .toggle span:before{-webkit-transform:rotate(45deg) translate(3px,3px);transform:rotate(45deg) translate(3px,3px)}.open-menu .toggle span:after{-webkit-transform:rotate(-45deg) translate(5px,-6px);transform:rotate(-45deg) translate(5px,-6px)}.caret{display:inline-block;width:0;height:0;margin-left:6px;vertical-align:middle;position:relative;top:-1px;border-top:4px solid;border-right:4px solid transparent;border-left:4px solid transparent}.sidebar{overflow:auto;height:100%;padding-right:15px;padding-bottom:15px;width:285px}.sidebar-wrapper{-webkit-overflow-scrolling:touch;background-color:#2B2F36;left:0;height:100%;overflow-y:hidden;position:fixed;top:0;width:285px;z-index:1}.sidebar-branding{width:160px;padding:0;margin:16px auto}.header{border-bottom:1px solid #E8E8E8;position:relative}.words,.characters{line-height:1rem;font-size:.8rem;margin-bottom:.77999rem;padding-top:.22001rem;font-weight:500;font-family:"Source Sans Pro","Helvetica Neue",Helvetica,Arial,sans-serif;color:#A0AABF;letter-spacing:1px;text-transform:uppercase;z-index:5;position:absolute;right:16px;top:0}.words span,.characters span{color:#000}.words+.characters{top:22px}.btn{text-align:center;display:inline-block;width:100%;text-transform:uppercase;font-weight:600;font-family:"Source Sans Pro","Helvetica Neue",Helvetica,Arial,sans-serif;font-size:14px;text-shadow:0 1px 0 #1b8b77;padding:16px 24px;background-color:#35D7BB;border-radius:3px;margin:0 auto 16px;line-height:1;color:#fff;-webkit-transition:all .15s linear;transition:all .15s linear;-webkit-font-smoothing:antialiased}.btn--new,.btn--save{display:block;width:238px}.btn--new:hover,.btn--new:focus,.btn--save:hover,.btn--save:focus{color:#fff;border-bottom-color:transparent;box-shadow:0 1px 3px #24b59c;text-shadow:0 1px 0 #24b59c}.btn--save{background-color:#4A5261;text-shadow:0 1px 1px #1e2127}.btn--save:hover,.btn--save:focus{color:#fff;border-bottom-color:transparent;box-shadow:0 1px 5px #08090a;text-shadow:none}.btn--delete{display:block;width:238px;background-color:transparent;font-size:12px;text-shadow:none}.btn--delete:hover,.btn--delete:focus{color:#fff;border-bottom-color:transparent;text-shadow:0 1px 0 #08090a;opacity:.8}.btn--delete-modal,.btn--ok,.btn--close{border-top:0;background-color:#4A5261;text-shadow:0 1px 0 #08090a;margin:0}.btn--delete-modal:hover,.btn--delete-modal:focus,.btn--ok:hover,.btn--ok:focus,.btn--close:hover,.btn--close:focus{color:#fff;background-color:#292d36;text-shadow:none}.btn--delete-modal{display:inline;width:auto}.overlay{position:absolute;top:0;left:0;width:100%;height:100%;background-color:rgba(55,61,73,.8);-webkit-transition:all .25s ease-in-out;transition:all .25s ease-in-out;-webkit-transition-timing-function:ease-out;transition-timing-function:ease-out;will-change:left,opacity,visibility;z-index:5;opacity:0;visibility:hidden}.show-settings .overlay{visibility:visible;opacity:1}.switch{float:right;line-height:1}.switch input{display:none}.switch small{display:inline-block;cursor:pointer;padding:0 24px 0 0;-webkit-transition:all ease .2s;transition:all ease .2s;background-color:#2B2F36;border-color:#2B2F36}.switch small,.switch small:before{border-radius:30px;box-shadow:inset 0 0 2px 0 #14171F}.switch small:before{display:block;content:'';width:28px;height:28px;background:#fff}.switch.checked small{padding-right:0;padding-left:24px;background-color:#35D7BB;box-shadow:none}.modal--dillinger.about .modal-dialog{font-size:1.25rem;max-width:500px}.modal--dillinger.scope .modal-dialog{max-width:300px;margin:5rem auto}.modal--dillinger .modal-dialog{max-width:600px;width:auto;margin:5rem auto}.modal--dillinger .modal-content{background:#373D49;border-radius:3px;box-shadow:0 2px 5px 0 #2C3B59;color:#fff;font-family:"Source Sans Pro","Helvetica Neue",Helvetica,Arial,sans-serif;font-weight:400;padding:2rem}.modal--dillinger ul{list-style-type:disc;margin:1rem 0;padding:0 0 0 1rem}.modal--dillinger li{padding:0;margin:0}.modal--dillinger .modal-header{border:0;padding:0}.modal--dillinger .modal-body{padding:0}.modal--dillinger .modal-footer{border:0;padding:0}.modal--dillinger .close{color:#fff;opacity:1}.modal-backdrop{background-color:#373D49}.pagination--dillinger{padding:0!important;margin:1.5rem 0!important;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-ms-flex-line-pack:stretch;align-content:stretch}.pagination--dillinger,.pagination--dillinger li{display:-webkit-box;display:-ms-flexbox;display:flex}.pagination--dillinger li{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;text-align:center}.pagination--dillinger li:first-child>a,.pagination--dillinger li.disabled>a,.pagination--dillinger li.disabled>a:hover,.pagination--dillinger li.disabled>a:focus,.pagination--dillinger li>a{background-color:transparent;border-color:#4F535B;border-right-color:transparent}.pagination--dillinger li.active>a,.pagination--dillinger li.active>a:hover,.pagination--dillinger li.active>a:focus{border-color:#4A5261;background-color:#4A5261;color:#fff}.pagination--dillinger li>a{float:none;color:#fff;width:100%;display:block;text-align:center;margin:0;border-right-color:transparent;padding:6px}.pagination--dillinger li>a:hover,.pagination--dillinger li>a:focus{border-color:#35D7BB;background-color:#35D7BB;color:#fff}.pagination--dillinger li:last-child a{border-color:#4F535B}.pagination--dillinger li:first-child a{border-right-color:transparent}.diNotify{position:absolute;z-index:9999;left:0;right:0;top:0;margin:0 auto;max-width:400px;text-align:center;-webkit-transition:top .5s ease-in-out,opacity .5s ease-in-out;transition:top .5s ease-in-out,opacity .5s ease-in-out;visibility:hidden}.diNotify-body{-webkit-font-smoothing:antialiased;background-color:#35D7BB;background:#666E7F;border-radius:3px;color:#fff;font-family:"Source Sans Pro","Helvetica Neue",Helvetica,Arial,sans-serif;font-weight:400;overflow:hidden;padding:1rem 2rem .5rem;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:baseline;-ms-flex-align:baseline;align-items:baseline;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center}.diNotify-icon{display:block;width:16px;height:16px;line-height:16px;position:relative;top:3px}.diNotify-message{padding-left:1rem}.zen-wrapper{position:fixed;top:0;left:0;right:0;bottom:0;width:100%;height:100%;z-index:10;background-color:#FFF;opacity:0;-webkit-transition:opacity .25s ease-in-out;transition:opacity .25s ease-in-out}.zen-wrapper.on{opacity:1}.enter-zen-mode{background-image:url("../img/icons/enter-zen.svg");right:.5rem;top:.313rem;display:none}.enter-zen-mode,.close-zen-mode{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;border:0;background-repeat:no-repeat;width:32px;height:32px;display:block;position:absolute}.close-zen-mode{background-image:url("../img/icons/exit-zen.svg");right:1rem;top:1rem}.zen-page{position:relative;top:0;bottom:0;z-index:11;height:100%;width:100%}#zen{font-size:1.25rem;width:300px;height:80%;margin:0 auto;position:relative;top:10%}#zen:before,#zen:after{content:"";position:absolute;height:10%;width:100%;z-index:12;pointer-events:none}#preview .table{width:auto}.ui-resizable{position:relative}.ui-resizable-handle{position:absolute;font-size:.1px;z-index:99999;display:block}.ui-resizable-e{background-color:#666;border-right:8px solid #e8e8e8;border-left:1px solid #222;width:10px;z-index:88!important;position:relative}.ui-resizable-e:after{content:"-";display:block;position:absolute;top:calc(50% - 16px);left:0;height:25px;width:2px;background-color:rgba(0,0,0,.4);margin:3px}#editor{cursor:ew-resize;position:relative;z-index:auto}.profile-pic{float:left;width:250px}#_default_ a::before{color:#A0AABF}#_default_ img{display:none}#_default_ #_default_{display:block;float:left;max-width:38%;word-wrap:break-word}#_default_ .default-ad{display:none}#_default_ ._default_{display:block}#_default_ a{color:#35d7bb;text-decoration:none}#_default_ a:hover{color:#8ae8d8}#_default_ .default-image{display:none}#_default_ .default-title:after{content:""}#_default_ .default-title,#_default_ .default-description{display:inline}#_default_ .default-title{position:relative;font-weight:600;display:none}#_default_ a:before{position:relative;top:0;padding:5px;color:#a0aabf;content:"Ad";text-transform:uppercase;font-size:8px;font-family:Verdana,sans-serif}#_default_{display:block;float:left;max-width:38%;word-wrap:break-word}#_default_ ._default_{display:block;font-size:.75rem;height:51px;letter-spacing:1px;line-height:1rem;padding:18px 24px}.split{overflow:scroll;padding:0!important}.split-editor{padding-left:0;padding-right:0;position:relative;z-index:3}.show-preview .split-editor{display:none}.split-preview{background-color:#fff;display:none;top:0;position:relative;z-index:4}.show-preview .split-preview{display:block}#editor{font-size:1rem;font-family:"Ubuntu Mono",Monaco;font-weight:400;line-height:2rem;width:100%;height:100%}#editor .ace_gutter{-webkit-font-smoothing:antialiased}.editor-header{width:50%;float:left;border-bottom:1px solid #E8E8E8;position:relative}.editor-header--first{border-right:1px solid #E8E8E8}.editor-header .title{display:inline-block}.preview-html{padding:15px}.preview-html a{color:#A0AABF;text-decoration:underline}.preview-src{white-space:normal}.preview-mode-toggle-src{background-image:url("../img/icons/code.svg")}.preview-mode-toggle-src,.preview-mode-toggle-html{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;border:0;background-repeat:no-repeat;width:32px;height:32px;display:block;position:absolute;right:.5rem;top:.5rem;display:none}.preview-mode-toggle-html{background-image:url("../img/icons/eye.svg")}.sr-only{visibility:hidden;text-overflow:110%;overflow:hidden;top:-100px;position:absolute}.mnone{margin:0!important}@media screen and (min-width:27.5em){html{font-size:.875em}body{font-size:1rem}ul,ol{margin-bottom:.83999rem;padding-top:.16001rem}p{padding-top:.66001rem}p,pre{margin-bottom:1.33999rem}pre,blockquote p{font-size:1rem;padding-top:.66001rem}blockquote p{margin-bottom:.33999rem}h1{font-size:2.0571429rem;margin-bottom:.21999rem;padding-top:.78001rem}h2{font-size:1.953125rem;margin-bottom:.1835837rem;padding-top:.8164163rem}h3{font-size:1.6457143rem;margin-bottom:.07599rem;padding-top:.92401rem}h4{font-size:1.5625rem;margin-bottom:.546865rem;padding-top:.453135rem}h5{font-size:1.25rem;margin-bottom:-.56251rem;padding-top:.56251rem}h6{font-size:1rem;margin-bottom:-.65001rem;padding-top:.65001rem}.g{margin-left:-16px;margin-right:-16px}.g-b{padding-left:16px;padding-right:16px}.g-b--m1of1{width:100%}.g-b--m1of2,.g-b--m2of4,.g-b--m3of6,.g-b--m4of8,.g-b--m5of10,.g-b--m6of12{width:50%}.g-b--m1of3,.g-b--m2of6,.g-b--m4of12{width:33.333%}.g-b--m2of3,.g-b--m4of6,.g-b--m8of12{width:66.666%}.g-b--m1of4,.g-b--m2of8,.g-b--m3of12{width:25%}.g-b--m3of4,.g-b--m6of8,.g-b--m9of12{width:75%}.g-b--m1of5,.g-b--m2of10{width:20%}.g-b--m2of5,.g-b--m4of10{width:40%}.g-b--m3of5,.g-b--m6of10{width:60%}.g-b--m4of5,.g-b--m8of10{width:80%}.g-b--m1of6,.g-b--m2of12{width:16.666%}.g-b--m5of6,.g-b--m10of12{width:83.333%}.g-b--m1of8{width:12.5%}.g-b--m3of8{width:37.5%}.g-b--m5of8{width:62.5%}.g-b--m7of8{width:87.5%}.g-b--m1of10{width:10%}.g-b--m3of10{width:30%}.g-b--m7of10{width:70%}.g-b--m9of10{width:90%}.g-b--m1of12{width:8.333%}.g-b--m5of12{width:41.666%}.g-b--m7of12{width:58.333%}.g-b--m11of12{width:91.666%}.g-b--push--m1of1{margin-left:100%}.g-b--push--m1of2,.g-b--push--m2of4,.g-b--push--m3of6,.g-b--push--m4of8,.g-b--push--m5of10,.g-b--push--m6of12{margin-left:50%}.g-b--push--m1of3,.g-b--push--m2of6,.g-b--push--m4of12{margin-left:33.333%}.g-b--push--m2of3,.g-b--push--m4of6,.g-b--push--m8of12{margin-left:66.666%}.g-b--push--m1of4,.g-b--push--m2of8,.g-b--push--m3of12{margin-left:25%}.g-b--push--m3of4,.g-b--push--m6of8,.g-b--push--m9of12{margin-left:75%}.g-b--push--m1of5,.g-b--push--m2of10{margin-left:20%}.g-b--push--m2of5,.g-b--push--m4of10{margin-left:40%}.g-b--push--m3of5,.g-b--push--m6of10{margin-left:60%}.g-b--push--m4of5,.g-b--push--m8of10{margin-left:80%}.g-b--push--m1of6,.g-b--push--m2of12{margin-left:16.666%}.g-b--push--m5of6,.g-b--push--m10of12{margin-left:83.333%}.g-b--push--m1of8{margin-left:12.5%}.g-b--push--m3of8{margin-left:37.5%}.g-b--push--m5of8{margin-left:62.5%}.g-b--push--m7of8{margin-left:87.5%}.g-b--push--m1of10{margin-left:10%}.g-b--push--m3of10{margin-left:30%}.g-b--push--m7of10{margin-left:70%}.g-b--push--m9of10{margin-left:90%}.g-b--push--m1of12{margin-left:8.333%}.g-b--push--m5of12{margin-left:41.666%}.g-b--push--m7of12{margin-left:58.333%}.g-b--push--m11of12{margin-left:91.666%}.g-b--pull--m1of1{margin-right:100%}.g-b--pull--m1of2,.g-b--pull--m2of4,.g-b--pull--m3of6,.g-b--pull--m4of8,.g-b--pull--m5of10,.g-b--pull--m6of12{margin-right:50%}.g-b--pull--m1of3,.g-b--pull--m2of6,.g-b--pull--m4of12{margin-right:33.333%}.g-b--pull--m2of3,.g-b--pull--m4of6,.g-b--pull--m8of12{margin-right:66.666%}.g-b--pull--m1of4,.g-b--pull--m2of8,.g-b--pull--m3of12{margin-right:25%}.g-b--pull--m3of4,.g-b--pull--m6of8,.g-b--pull--m9of12{margin-right:75%}.g-b--pull--m1of5,.g-b--pull--m2of10{margin-right:20%}.g-b--pull--m2of5,.g-b--pull--m4of10{margin-right:40%}.g-b--pull--m3of5,.g-b--pull--m6of10{margin-right:60%}.g-b--pull--m4of5,.g-b--pull--m8of10{margin-right:80%}.g-b--pull--m1of6,.g-b--pull--m2of12{margin-right:16.666%}.g-b--pull--m5of6,.g-b--pull--m10of12{margin-right:83.333%}.g-b--pull--m1of8{margin-right:12.5%}.g-b--pull--m3of8{margin-right:37.5%}.g-b--pull--m5of8{margin-right:62.5%}.g-b--pull--m7of8{margin-right:87.5%}.g-b--pull--m1of10{margin-right:10%}.g-b--pull--m3of10{margin-right:30%}.g-b--pull--m7of10{margin-right:70%}.g-b--pull--m9of10{margin-right:90%}.g-b--pull--m1of12{margin-right:8.333%}.g-b--pull--m5of12{margin-right:41.666%}.g-b--pull--m7of12{margin-right:58.333%}.g-b--pull--m11of12{margin-right:91.666%}.splashscreen p{font-size:1.25rem;margin-bottom:1.43749rem;padding-top:.56251rem}.title{font-size:.8rem;margin-bottom:.77999rem;padding-top:.22001rem}.title-document{margin-bottom:.89999rem;padding-top:.10001rem}.title-document,.settings a{font-size:1.25rem}.words,.characters{font-size:.8rem;margin-bottom:.77999rem;padding-top:.22001rem}.modal--dillinger.about .modal-dialog,#zen{font-size:1.25rem}#zen{width:400px}#editor{font-size:1rem}}@media screen and (min-width:46.25em){html{font-size:.875em}body{font-size:1rem}ul,ol{margin-bottom:.83999rem;padding-top:.16001rem}p{padding-top:.66001rem}p,pre{margin-bottom:1.33999rem}pre,blockquote p{font-size:1rem;padding-top:.66001rem}blockquote p{margin-bottom:.33999rem}h1{font-size:2.0571429rem;margin-bottom:.21999rem;padding-top:.78001rem}h2{font-size:1.953125rem;margin-bottom:.1835837rem;padding-top:.8164163rem}h3{font-size:1.6457143rem;margin-bottom:.07599rem;padding-top:.92401rem}h4{font-size:1.5625rem;margin-bottom:.546865rem;padding-top:.453135rem}h5{font-size:1.25rem;margin-bottom:-.56251rem;padding-top:.56251rem}h6{font-size:1rem;margin-bottom:-.65001rem;padding-top:.65001rem}.g{margin-left:-16px;margin-right:-16px}.g-b{padding-left:16px;padding-right:16px}.g-b--t1of1{width:100%}.g-b--t1of2,.g-b--t2of4,.g-b--t3of6,.g-b--t4of8,.g-b--t5of10,.g-b--t6of12{width:50%}.g-b--t1of3,.g-b--t2of6,.g-b--t4of12{width:33.333%}.g-b--t2of3,.g-b--t4of6,.g-b--t8of12{width:66.666%}.g-b--t1of4,.g-b--t2of8,.g-b--t3of12{width:25%}.g-b--t3of4,.g-b--t6of8,.g-b--t9of12{width:75%}.g-b--t1of5,.g-b--t2of10{width:20%}.g-b--t2of5,.g-b--t4of10{width:40%}.g-b--t3of5,.g-b--t6of10{width:60%}.g-b--t4of5,.g-b--t8of10{width:80%}.g-b--t1of6,.g-b--t2of12{width:16.666%}.g-b--t5of6,.g-b--t10of12{width:83.333%}.g-b--t1of8{width:12.5%}.g-b--t3of8{width:37.5%}.g-b--t5of8{width:62.5%}.g-b--t7of8{width:87.5%}.g-b--t1of10{width:10%}.g-b--t3of10{width:30%}.g-b--t7of10{width:70%}.g-b--t9of10{width:90%}.g-b--t1of12{width:8.333%}.g-b--t5of12{width:41.666%}.g-b--t7of12{width:58.333%}.g-b--t11of12{width:91.666%}.g-b--push--t1of1{margin-left:100%}.g-b--push--t1of2,.g-b--push--t2of4,.g-b--push--t3of6,.g-b--push--t4of8,.g-b--push--t5of10,.g-b--push--t6of12{margin-left:50%}.g-b--push--t1of3,.g-b--push--t2of6,.g-b--push--t4of12{margin-left:33.333%}.g-b--push--t2of3,.g-b--push--t4of6,.g-b--push--t8of12{margin-left:66.666%}.g-b--push--t1of4,.g-b--push--t2of8,.g-b--push--t3of12{margin-left:25%}.g-b--push--t3of4,.g-b--push--t6of8,.g-b--push--t9of12{margin-left:75%}.g-b--push--t1of5,.g-b--push--t2of10{margin-left:20%}.g-b--push--t2of5,.g-b--push--t4of10{margin-left:40%}.g-b--push--t3of5,.g-b--push--t6of10{margin-left:60%}.g-b--push--t4of5,.g-b--push--t8of10{margin-left:80%}.g-b--push--t1of6,.g-b--push--t2of12{margin-left:16.666%}.g-b--push--t5of6,.g-b--push--t10of12{margin-left:83.333%}.g-b--push--t1of8{margin-left:12.5%}.g-b--push--t3of8{margin-left:37.5%}.g-b--push--t5of8{margin-left:62.5%}.g-b--push--t7of8{margin-left:87.5%}.g-b--push--t1of10{margin-left:10%}.g-b--push--t3of10{margin-left:30%}.g-b--push--t7of10{margin-left:70%}.g-b--push--t9of10{margin-left:90%}.g-b--push--t1of12{margin-left:8.333%}.g-b--push--t5of12{margin-left:41.666%}.g-b--push--t7of12{margin-left:58.333%}.g-b--push--t11of12{margin-left:91.666%}.g-b--pull--t1of1{margin-right:100%}.g-b--pull--t1of2,.g-b--pull--t2of4,.g-b--pull--t3of6,.g-b--pull--t4of8,.g-b--pull--t5of10,.g-b--pull--t6of12{margin-right:50%}.g-b--pull--t1of3,.g-b--pull--t2of6,.g-b--pull--t4of12{margin-right:33.333%}.g-b--pull--t2of3,.g-b--pull--t4of6,.g-b--pull--t8of12{margin-right:66.666%}.g-b--pull--t1of4,.g-b--pull--t2of8,.g-b--pull--t3of12{margin-right:25%}.g-b--pull--t3of4,.g-b--pull--t6of8,.g-b--pull--t9of12{margin-right:75%}.g-b--pull--t1of5,.g-b--pull--t2of10{margin-right:20%}.g-b--pull--t2of5,.g-b--pull--t4of10{margin-right:40%}.g-b--pull--t3of5,.g-b--pull--t6of10{margin-right:60%}.g-b--pull--t4of5,.g-b--pull--t8of10{margin-right:80%}.g-b--pull--t1of6,.g-b--pull--t2of12{margin-right:16.666%}.g-b--pull--t5of6,.g-b--pull--t10of12{margin-right:83.333%}.g-b--pull--t1of8{margin-right:12.5%}.g-b--pull--t3of8{margin-right:37.5%}.g-b--pull--t5of8{margin-right:62.5%}.g-b--pull--t7of8{margin-right:87.5%}.g-b--pull--t1of10{margin-right:10%}.g-b--pull--t3of10{margin-right:30%}.g-b--pull--t7of10{margin-right:70%}.g-b--pull--t9of10{margin-right:90%}.g-b--pull--t1of12{margin-right:8.333%}.g-b--pull--t5of12{margin-right:41.666%}.g-b--pull--t7of12{margin-right:58.333%}.g-b--pull--t11of12{margin-right:91.666%}.splashscreen-dillinger{width:500px}.splashscreen p{font-size:1.25rem;margin-bottom:1.43749rem;padding-top:.56251rem}.title{font-size:.8rem;margin-bottom:.77999rem;padding-top:.22001rem}.title-document{font-size:1.25rem;margin-bottom:.89999rem;padding-top:.10001rem}.menu .menu-item--save-to,.menu .menu-item--import-from{display:block}.menu .menu-item--preview,.menu .menu-item--save-to.in-sidebar,.menu .menu-item--import-from.in-sidebar{display:none}.settings a{font-size:1.25rem}.words,.characters{font-size:.8rem;margin-bottom:.77999rem;padding-top:.22001rem}.modal--dillinger.about .modal-dialog{font-size:1.25rem}.enter-zen-mode{display:block}.close-zen-mode{right:3rem;top:3rem}#zen{font-size:1.25rem;width:500px}.split-editor{border-right:1px solid #E8E8E8;float:left;height:calc(100vh - 172px);-webkit-overflow-scrolling:touch;padding-right:16px;width:50%}.show-preview .split-editor{display:block}.split-preview{display:block;float:right;height:calc(100vh - 172px);-webkit-overflow-scrolling:touch;position:relative;top:0;width:50%}#editor{font-size:1rem}.preview-mode-toggle-src,.preview-mode-toggle-html{display:block}}@media screen and (min-width:62.5em){html{font-size:.875em}body{font-size:1rem}ul,ol{margin-bottom:.83999rem;padding-top:.16001rem}p{padding-top:.66001rem}p,pre{margin-bottom:1.33999rem}pre,blockquote p{font-size:1rem;padding-top:.66001rem}blockquote p{margin-bottom:.33999rem}h1{font-size:2.0571429rem;margin-bottom:.21999rem;padding-top:.78001rem}h2{font-size:1.953125rem;margin-bottom:.1835837rem;padding-top:.8164163rem}h3{font-size:1.6457143rem;margin-bottom:.07599rem;padding-top:.92401rem}h4{font-size:1.5625rem;margin-bottom:.546865rem;padding-top:.453135rem}h5{font-size:1.25rem;margin-bottom:-.56251rem;padding-top:.56251rem}h6{font-size:1rem;margin-bottom:-.65001rem;padding-top:.65001rem}.g{margin-left:-16px;margin-right:-16px}.g-b{padding-left:16px;padding-right:16px}.g-b--d1of1{width:100%}.g-b--d1of2,.g-b--d2of4,.g-b--d3of6,.g-b--d4of8,.g-b--d5of10,.g-b--d6of12{width:50%}.g-b--d1of3,.g-b--d2of6,.g-b--d4of12{width:33.333%}.g-b--d2of3,.g-b--d4of6,.g-b--d8of12{width:66.666%}.g-b--d1of4,.g-b--d2of8,.g-b--d3of12{width:25%}.g-b--d3of4,.g-b--d6of8,.g-b--d9of12{width:75%}.g-b--d1of5,.g-b--d2of10{width:20%}.g-b--d2of5,.g-b--d4of10{width:40%}.g-b--d3of5,.g-b--d6of10{width:60%}.g-b--d4of5,.g-b--d8of10{width:80%}.g-b--d1of6,.g-b--d2of12{width:16.666%}.g-b--d5of6,.g-b--d10of12{width:83.333%}.g-b--d1of8{width:12.5%}.g-b--d3of8{width:37.5%}.g-b--d5of8{width:62.5%}.g-b--d7of8{width:87.5%}.g-b--d1of10{width:10%}.g-b--d3of10{width:30%}.g-b--d7of10{width:70%}.g-b--d9of10{width:90%}.g-b--d1of12{width:8.333%}.g-b--d5of12{width:41.666%}.g-b--d7of12{width:58.333%}.g-b--d11of12{width:91.666%}.g-b--push--d1of1{margin-left:100%}.g-b--push--d1of2,.g-b--push--d2of4,.g-b--push--d3of6,.g-b--push--d4of8,.g-b--push--d5of10,.g-b--push--d6of12{margin-left:50%}.g-b--push--d1of3,.g-b--push--d2of6,.g-b--push--d4of12{margin-left:33.333%}.g-b--push--d2of3,.g-b--push--d4of6,.g-b--push--d8of12{margin-left:66.666%}.g-b--push--d1of4,.g-b--push--d2of8,.g-b--push--d3of12{margin-left:25%}.g-b--push--d3of4,.g-b--push--d6of8,.g-b--push--d9of12{margin-left:75%}.g-b--push--d1of5,.g-b--push--d2of10{margin-left:20%}.g-b--push--d2of5,.g-b--push--d4of10{margin-left:40%}.g-b--push--d3of5,.g-b--push--d6of10{margin-left:60%}.g-b--push--d4of5,.g-b--push--d8of10{margin-left:80%}.g-b--push--d1of6,.g-b--push--d2of12{margin-left:16.666%}.g-b--push--d5of6,.g-b--push--d10of12{margin-left:83.333%}.g-b--push--d1of8{margin-left:12.5%}.g-b--push--d3of8{margin-left:37.5%}.g-b--push--d5of8{margin-left:62.5%}.g-b--push--d7of8{margin-left:87.5%}.g-b--push--d1of10{margin-left:10%}.g-b--push--d3of10{margin-left:30%}.g-b--push--d7of10{margin-left:70%}.g-b--push--d9of10{margin-left:90%}.g-b--push--d1of12{margin-left:8.333%}.g-b--push--d5of12{margin-left:41.666%}.g-b--push--d7of12{margin-left:58.333%}.g-b--push--d11of12{margin-left:91.666%}.g-b--pull--d1of1{margin-right:100%}.g-b--pull--d1of2,.g-b--pull--d2of4,.g-b--pull--d3of6,.g-b--pull--d4of8,.g-b--pull--d5of10,.g-b--pull--d6of12{margin-right:50%}.g-b--pull--d1of3,.g-b--pull--d2of6,.g-b--pull--d4of12{margin-right:33.333%}.g-b--pull--d2of3,.g-b--pull--d4of6,.g-b--pull--d8of12{margin-right:66.666%}.g-b--pull--d1of4,.g-b--pull--d2of8,.g-b--pull--d3of12{margin-right:25%}.g-b--pull--d3of4,.g-b--pull--d6of8,.g-b--pull--d9of12{margin-right:75%}.g-b--pull--d1of5,.g-b--pull--d2of10{margin-right:20%}.g-b--pull--d2of5,.g-b--pull--d4of10{margin-right:40%}.g-b--pull--d3of5,.g-b--pull--d6of10{margin-right:60%}.g-b--pull--d4of5,.g-b--pull--d8of10{margin-right:80%}.g-b--pull--d1of6,.g-b--pull--d2of12{margin-right:16.666%}.g-b--pull--d5of6,.g-b--pull--d10of12{margin-right:83.333%}.g-b--pull--d1of8{margin-right:12.5%}.g-b--pull--d3of8{margin-right:37.5%}.g-b--pull--d5of8{margin-right:62.5%}.g-b--pull--d7of8{margin-right:87.5%}.g-b--pull--d1of10{margin-right:10%}.g-b--pull--d3of10{margin-right:30%}.g-b--pull--d7of10{margin-right:70%}.g-b--pull--d9of10{margin-right:90%}.g-b--pull--d1of12{margin-right:8.333%}.g-b--pull--d5of12{margin-right:41.666%}.g-b--pull--d7of12{margin-right:58.333%}.g-b--pull--d11of12{margin-right:91.666%}.splashscreen-dillinger{width:700px}.splashscreen p{font-size:1.25rem;margin-bottom:1.43749rem;padding-top:.56251rem}.title{font-size:.8rem;margin-bottom:.77999rem;padding-top:.22001rem}.title-document{font-size:1.25rem;margin-bottom:.89999rem;padding-top:.10001rem}.menu .menu-item--export-as{display:block}.menu .menu-item--preview{display:none}.settings a{font-size:1.25rem}.words,.characters{font-size:.8rem;margin-bottom:.77999rem;padding-top:.22001rem}.modal--dillinger.about .modal-dialog,#zen{font-size:1.25rem}#zen{width:700px}#editor{font-size:1rem}}@media screen and (min-width:87.5em){html{font-size:.875em}body{font-size:1rem}ul,ol{margin-bottom:.83999rem;padding-top:.16001rem}p{padding-top:.66001rem}p,pre{margin-bottom:1.33999rem}pre,blockquote p{font-size:1rem;padding-top:.66001rem}blockquote p{margin-bottom:.33999rem}h1{font-size:2.0571429rem;margin-bottom:.21999rem;padding-top:.78001rem}h2{font-size:1.953125rem;margin-bottom:.1835837rem;padding-top:.8164163rem}h3{font-size:1.6457143rem;margin-bottom:.07599rem;padding-top:.92401rem}h4{font-size:1.5625rem;margin-bottom:.546865rem;padding-top:.453135rem}h5{font-size:1.25rem;margin-bottom:-.56251rem;padding-top:.56251rem}h6{font-size:1rem;margin-bottom:-.65001rem;padding-top:.65001rem}.splashscreen-dillinger{width:800px}.splashscreen p{font-size:1.25rem;margin-bottom:1.43749rem;padding-top:.56251rem}.title{font-size:.8rem;margin-bottom:.77999rem;padding-top:.22001rem}.title-document{margin-bottom:.89999rem;padding-top:.10001rem}.title-document,.settings a{font-size:1.25rem}.words,.characters{font-size:.8rem;margin-bottom:.77999rem;padding-top:.22001rem}.modal--dillinger.about .modal-dialog,#zen{font-size:1.25rem}#editor{font-size:1rem}}@media (min-width:768px){.form-inline .form-group{display:inline-block;margin-bottom:0;vertical-align:middle}.form-inline .form-control{display:inline-block;width:auto;vertical-align:middle}.form-inline .input-group{display:inline-table;vertical-align:middle}.form-inline .input-group .input-group-addon,.form-inline .input-group .input-group-btn,.form-inline .input-group .form-control{width:auto}.form-inline .input-group>.form-control{width:100%}.form-inline .control-label{margin-bottom:0;vertical-align:middle}.form-inline .radio,.form-inline .checkbox{display:inline-block;margin-top:0;margin-bottom:0;vertical-align:middle}.form-inline .radio label,.form-inline .checkbox label{padding-left:0}.form-inline .radio input[type="radio"],.form-inline .checkbox input[type="checkbox"]{position:relative;margin-left:0}.form-inline .has-feedback .form-control-feedback{top:0}.form-horizontal .control-label{text-align:right;margin-bottom:0;padding-top:7px}.form-horizontal .form-group-lg .control-label{padding-top:14.3px}.form-horizontal .form-group-sm .control-label{padding-top:6px}.modal-dialog{width:600px;margin:30px auto}.modal-content{box-shadow:0 5px 15px rgba(0,0,0,.5)}.modal-sm{width:300px}}@media (min-width:992px){.modal-lg{width:900px}}@media screen and (max-width:1200px){#_default_{max-width:30%}#_default_ ._default_{font-size:.825rem;line-height:.875rem;padding:12px 12px 6px 24px;text-align:justify}}@media screen and (max-width:1100px){#_default_{max-width:27%}#_default_ ._default_{font-size:.8rem;line-height:.85rem;padding:12px 6px 6px 24px;text-align:justify}}@media screen and (max-width:1000px){#_default_{max-width:24%}#_default_ ._default_{font-size:.775rem;line-height:.8rem;padding:12px 6px 6px 24px;text-align:justify}}@media screen and (max-width:900px){#_default_{max-width:30%}}@media screen and (max-width:767px){.table-responsive{width:100%;margin-bottom:15px;overflow-y:hidden;overflow-x:auto;-ms-overflow-style:-ms-autohiding-scrollbar;border:1px solid #ddd;-webkit-overflow-scrolling:touch}.table-responsive>.table{margin-bottom:0}.table-responsive>.table>thead>tr>th,.table-responsive>.table>thead>tr>td,.table-responsive>.table>tbody>tr>th,.table-responsive>.table>tbody>tr>td,.table-responsive>.table>tfoot>tr>th,.table-responsive>.table>tfoot>tr>td{white-space:nowrap}.table-responsive>.table-bordered{border:0}.table-responsive>.table-bordered>thead>tr>th:first-child,.table-responsive>.table-bordered>thead>tr>td:first-child,.table-responsive>.table-bordered>tbody>tr>th:first-child,.table-responsive>.table-bordered>tbody>tr>td:first-child,.table-responsive>.table-bordered>tfoot>tr>th:first-child,.table-responsive>.table-bordered>tfoot>tr>td:first-child{border-left:0}.table-responsive>.table-bordered>thead>tr>th:last-child,.table-responsive>.table-bordered>thead>tr>td:last-child,.table-responsive>.table-bordered>tbody>tr>th:last-child,.table-responsive>.table-bordered>tbody>tr>td:last-child,.table-responsive>.table-bordered>tfoot>tr>th:last-child,.table-responsive>.table-bordered>tfoot>tr>td:last-child{border-right:0}.table-responsive>.table-bordered>tbody>tr:last-child>th,.table-responsive>.table-bordered>tbody>tr:last-child>td,.table-responsive>.table-bordered>tfoot>tr:last-child>th,.table-responsive>.table-bordered>tfoot>tr:last-child>td{border-bottom:0}}@media screen and (max-width:720px){#_default_{max-width:60%}#_default_ ._default_{font-size:.75rem;line-height:1rem;padding:12px 24px}}@media screen and (max-width:620px){#_default_{max-width:50%}#_default_ ._default_{font-size:.66rem;letter-spacing:1px;line-height:1rem;padding:10px 24px}}@media screen and (max-width:520px){#_default_ ._default_{font-size:.4rem;line-height:.875rem;padding:6px 12px 6px 24px;text-align:justify}}@media screen and (max-width:460px){#_default_{display:none}}@media screen and (max-width:46.1875em){.editor-header{display:none}.editor-header--first{display:block;width:100%}}</style></head><body id="preview">
<h1><a id="zCymatixhttpwwwzcymatixcom_Natural_Language_UnderstandingNLU_Voicetext_UI__Expert_Systems_Platform_0"></a><a href="http://www.zcymatix.com">zCymatix</a> Natural Language Understanding(NLU) Voice/text UI &amp; Expert Systems Platform</h1>
<h1><a id="Sign_Uphttpsnlp2zcymatixcom_1"></a><a href="https://nlp2.zcymatix.com/">Sign Up</a></h1>
<h1><a id="Dashboard_Android_Apphttpsplaygooglecomstoreappsdetailsidcomzcymatixdemo_2"></a><a href="https://play.google.com/store/apps/details?id=com.zcymatix.demo">Dashboard Android App</a></h1>
<h4><a id="Applications_3"></a>Applications:</h4>
<ul>
<li>Healthcare</li>
<li>Finance</li>
<li>Electronics</li>
<li>Wearables/IoT</li>
<li>Automotive</li>
<li>Web sites for blind people</li>
<li>Interactive (Voice/text controlled) Web sites.</li>
<li>Emails/text scans and more</li>
</ul>
<h1><a id="Table_of_Contents_14"></a>Table of Contents</h1>
<ul>
<li><a href="#Features_Highlights_87">Features Highlights</a></li>
<li><a href="#Hello_Word_Example_130">Hello Word Example</a></li>
<li><a href="#Project_Layers_166">Project Layers</a></li>
<li><a href="#Project_ID_174">Project ID</a></li>
<li><a href="#Training_time_178">Training time</a></li>
<li><a href="#Project_WEB_UI_indicators_181">Project WEB UI indicators</a></li>
<li><a href="#NLU_service_REST_API_190">NLU service REST API</a>
<ul>
<li><a href="#Launch_request_191">Launch request</a></li>
<li><a href="#Inference_example_225">Inference example</a></li>
<li><a href="#List_of_response_codes_239">List of response codes</a></li>
</ul>
</li>
<li><a href="#train_section_253">.train section</a></li>
<li><a href="#prompt_section_272">.prompt section</a></li>
<li><a href="#define_section_301">.define section</a></li>
<li><a href="#list_section_326">.list section</a></li>
<li><a href="#Slots_parameters_352">Slots (parameters)</a></li>
<li><a href="#Introduction_to_Layers_371">Introduction to Layers</a></li>
<li><a href="#Dialogs_445">Dialogs</a>
<ul>
<li><a href="#AI_system_asks_questions_447">AI system asks questions</a>
<ul>
<li><a href="#gate_section_492">.gate section</a></li>
</ul>
</li>
<li><a href="#User_asks_questions_535">User asks questions</a></li>
</ul>
</li>
<li><a href="#regex_section_574">.regex section</a>
<ul>
<li><a href="#Replacement_575">Replacement</a></li>
<li><a href="#Lookup_lables_588">Lookup lables</a></li>
</ul>
</li>
<li><a href="#Prompt_label_596">Prompt label</a>
<ul>
<li><a href="#prefix-">Prefix &lt;strong&gt;&quot;#&quot;&lt;/strong&gt;</a></li>
<li><a href="#prefix--1">Prefix &lt;strong&gt;&quot;?#&quot;&lt;/strong&gt;</a></li>
<li><a href="#prefix--2">Prefix &lt;strong&gt;&quot;$&quot;&lt;/strong&gt;</a></li>
<li><a href="#prefix--3">Prefix &lt;strong&gt;&quot;?$&quot;&lt;/strong&gt;</a></li>
<li><a href="#prefix--4">Prefix &lt;strong&gt;&quot;.&quot;&lt;/strong&gt;</a></li>
<li><a href="#prefix--5">Prefix &lt;strong&gt;&quot;?.&quot;&lt;/strong&gt;</a></li>
<li><a href="#Empty_label_prefix_673">Empty label prefix</a></li>
<li><a href="#prefix--6">Prefix &lt;strong&gt;&quot;?&quot;&lt;/strong&gt;</a></li>
<li><a href="#Prompt_label_value_access_by_index_690">Prompt label value access by index</a></li>
</ul>
</li>
<li><a href="#PIZZA2_BOT_Example_707">PIZZA2 BOT Example</a>
<ul>
<li><a href="#Layer_1_Slots_709">Layer 1 Slots</a></li>
<li><a href="#Layer_2_Pizza_807">Layer 2 Pizza</a></li>
<li><a href="#Layer_3_Bot_886">Layer 3 Bot</a></li>
<li><a href="#Pizza_project_Final_Inference_912">Pizza project Final Inference</a></li>
</ul>
</li>
<li><a href="#Inference_history_932">Inference history</a></li>
<li><a href="#How_to_control_inference_history_939">How to control inference history</a>
<ul>
<li><a href="#Intent_Prefixes_942">Intent Prefixes</a></li>
<li><a href="#Empty_prefix_954">Empty prefix</a></li>
<li><a href="#R_prefix_Return_command_960">R~ prefix. Return command</a></li>
<li><a href="#F_prefix_Infere_and_Forget_command_978">F~ prefix. Infere and Forget command</a></li>
<li><a href="#P_prefix_One_step_back_command_988">P~ prefix. One step back command</a></li>
<li><a href="#B_prefix_Two_steps_back_command_1005">B~ prefix. Two steps back command</a></li>
<li><a href="#C_prefix_Change_slot_value_command_1008">C~ prefix. Change slot value command</a></li>
<li><a href="#X_prefix_Clean_previous_history_command_1027">X~ prefix. Clean previous history command</a></li>
<li><a href="#I_prefix_Clean_previous_history_and_restart_command_1045">I~ prefix. Clean previous history and restart command</a></li>
</ul>
</li>
<li><a href="#Idioms_interpretation_Intent_prefix__1048">Idioms interpretation. Intent prefix ~</a></li>
<li><a href="#Remove_slot_value_from_inference_history_del_command_1062">Remove slot value from inference history. $del command</a></li>
<li><a href="#Coreference_1076">Coreference_1076</a></li>
<li><a href="#Script_sections_1095">Script sections</a>
<ul>
<li><a href="#gate2_section_1098">.gate2 section</a></li>
<li><a href="#script_section_1123">.script section</a></li>
<li><a href="#vars_section_1159">.vars section</a></li>
<li><a href="#slist_section_1162">.slist section</a></li>
</ul>
</li>
<li><a href="#Events_States_Sensors_Information_Embedding_1184">Events, States, Sensors Information Embedding</a></li>
<li><a href="#Multiple_language_support_1226">Multiple language support</a></li>
<li><a href="#Comments_in_training_files_1237">Comments in training files</a></li>
<li><a href="#Long_lines_continuation_1240">Long lines continuation</a></li>
<li><a href="#Unknown_word_marker_1243">Unknown word marker</a></li>
<li><a href="#Named_Entity_Recognition_1246">Named Entity Recognition</a></li>
<li><a href="#Expert_systems_support_1292">Expert systems support</a></li>
<li><a href="#Recommendations_tips_and_tricks_1295">Recommendations, tips and tricks</a></li>
<li><a href="#Optional_configuration_parameters_1348">Optional configuration parameters</a></li>
<li><a href="#Advanced_configuration_parameters_1474">Advanced configuration parameters</a></li>
</ul>
<h4><a id="Machine_learning_NLU_system_designed_for_dialogues_and_expert_systems_The_platform_utilizes_proprietary_TothTrain_Of_Thought_technology_for_conversation_flow_tracking_and_supports_many_other_features_85"></a>Machine learning NLU system designed for dialogues and expert systems. The platform utilizes proprietary Toth(Train Of Thought) technology for conversation flow tracking and supports many other features</h4>
<h3><a id="___Context_IS_everything_____86"></a><strong><em>Context IS everything </em></strong></h3>
<h1><a id="Features_Highlights_87"></a>Features Highlights</h1>
<ul>
<li><strong><em><code>Train Of Thought technology</code></em></strong>
<ul>
<li>Maintains a train of thought of the conversation using proprietary mechanism and inferences history</li>
</ul>
</li>
<li><strong><em><code>Session-based conversation instances</code></em></strong>  Memory and context is kept on the <code>backend</code>. Client application does not need to collect inference history(!).</li>
<li>Ability to create <strong><em><code>1000s of utterances</code></em></strong> in minutes</li>
<li><strong><em><code>States, Events and Sensors Data Embedding</code></em></strong> contextual support</li>
<li><strong><em><code>Scripting support</code></em></strong>
<ul>
<li>Along with <code>ToTh</code>, developer may choose to use python scripts that runs on backend to update inferences based on the context. This way client application focuses on the task at hand.</li>
</ul>
</li>
<li><code>Regex</code> support. Yes, why would you need to use trainable models for simple things.? You may, but you dont have to.</li>
<li>Idioms interpretation mechanism
<ul>
<li>I would really want to grab a bite and then go back home =&gt; <code>{ 't_intent':'NAVIGATE', 't_stopover':'restaurant', 't_dest':'Home' }</code></li>
</ul>
</li>
<li>Named Entity Recognition support
<ul>
<li>I want BBQ chicken and new york pizza =&gt; I want PIZZA_KIND and PIZZA_KIND pizza =&gt; <code>{ 't_intent':'ORDER_PIZZA', 't_kind':['BBQ chicken', 'new york']</code></li>
</ul>
</li>
<li>NLU tasks:
<ul>
<li><code>Self-contained</code> inferences:
<ul>
<li><strong>Play the latest from Def Leppard</strong> =&gt;<br>
<code>{ 't_intent':'PLAY_MUSIC', 't_artist':'Def Leppard', 't_attr':'latest' }</code></li>
<li><strong>Show flights to Seattle</strong> =&gt;  <code>{ 't_intent':'SHOW_FLIGHT, 't_dest':'Seattle' }</code></li>
</ul>
</li>
<li><code>AI Bot asks User</code> questions. Example: Order pizza bot
<ul>
<li>User&gt; <strong>I am hungry for pizza.</strong></li>
<li><strong>Bot</strong>&gt; What kind of pizza would you like?</li>
<li>User&gt; <strong>I would like BBQ chicken and pepperoni</strong></li>
<li><strong>Bot</strong>&gt; What toppings would you like?</li>
<li>User&gt; <strong>I will go with extra cheese and tomatoes on top</strong></li>
<li></li>
</ul>
</li>
<li><code>User asks AI bot</code> questions. Example: Web site How To section:
<ul>
<li>User&gt; <strong>What can you do for me?</strong></li>
<li><strong>Bot</strong>&gt; I can help you to create AI chat bots, make your website to talk to you and more</li>
<li>User&gt; <strong>how?</strong></li>
<li><strong>Bot</strong>&gt; First, you need to create a project</li>
<li>User&gt; <strong>How?</strong></li>
<li><strong>Bot</strong>&gt; Create a folder, then create configuration file and training files for me to learn</li>
</ul>
</li>
<li>Combination of above</li>
</ul>
</li>
<li><strong><em>Coreference Resolution</em></strong><br>
* Where is Seattle<br>
* Take me there</li>
<li><strong><em><code>Expert systems support</code></em></strong> Result of the dialog could be fed into a layer to process conversation outcome.
<ul>
<li>This is not NLU specific feature which enables platform utilization in any field of knowledge</li>
</ul>
</li>
<li><strong><em><code>Multiple language support</code></em></strong></li>
<li>NOTE! Platform DOES NOT provide voice recognition services</li>
</ul>
<p><strong><em>So, Lets do it!</em></strong></p>
<h1><a id="Hello_Word_Example_130"></a>Hello Word Example</h1>
<p>Lets demonstrate how 3 lines of text/code makes your first NLU project.</p>
<ul>
<li>Create and enter <strong>hello</strong> folder. <code>Folder name is the name of the project.</code></li>
<li>Create <strong>hello.json</strong> file</li>
</ul>
<pre><code class="language-json">{ "<span class="hljs-attribute">data_files</span>":<span class="hljs-value"><span class="hljs-string">"hello.txt"</span> </span>}
</code></pre>
<ul>
<li>Create <strong>hello.txt</strong> training file</li>
</ul>
<pre><code>.train
    GREETING: (Hello World|hi|hello)
</code></pre>
<p><strong><em>GREETING</em></strong> is the <strong><em>intent</em></strong>, Hello world is how you say it. You may ask what if the intent is not specified? Well - this means that utterance Hello World will not have any associations. This is very important point to understand - you can describe things two ways a) by what <strong><em>it is</em></strong> and b) what <strong><em>it is not</em></strong>. We will come to this later.<br>
So, this is it. Literally, 3 lines of code get you there. The inference of the phrase Hello World will be</p>
<pre><code class="language-json">    {"<span class="hljs-attribute">t_intent</span>":<span class="hljs-value"><span class="hljs-string">"GREETING"</span></span>}
</code></pre>
<p>Thats it. If you want to see system to respond to you, add:</p>
<pre><code>.prompt
    GREETING: Hello my friend
</code></pre>
<p>To get end-to-end experience go to <a href="http://www.zcymatix.com">zcymatix.com</a> and sign up. Press <strong><em>Sign In</em></strong> and then <strong><em>Sign Up</em></strong>.<br>
<strong><em>NOTE!</em></strong> Please use real e-mail address to be able to receive training completion notification with PROJECT ID. Otherwise you cannot use the service.<br>
<img src="http://www.zcymatix.com/img/signup3.png" alt="Register" title="Register"></p>
<p>After login, upload the project by choosing your project folder - <strong><em>hello</em></strong>.<br>
Remember, <strong>project name</strong> is the name of the <strong>folder</strong> and configuration file name must be<br>
<code>&lt;project name&gt;.json</code><br>
<img src="http://www.zcymatix.com/img/upload_page1.png" alt="Upload" title="Upload"></p>
<p>When project is uploaded, you need to train it. Choose <strong><em>Build</em></strong> option for that. When project was stopped and/or you want to continue building it, press <strong><em>Continue Build</em></strong>. However, keep in mind that if you changed the training files, continuing building the project DOES NOT always means faster training times. So, we suggest to use <strong><em>Build</em></strong> option when training files have changed.<br>
Option <strong><em>Start/Restart</em></strong> launches the project in production mode. It should be used when project has been already built. NOTE! You <strong><em>can</em></strong> start building the project while it is in launched/production mode (we use these terms interchangeably). Once the building is finished, the project will <code>go online without distrupting client applications</code>.<br>
<img src="http://www.zcymatix.com/img/launch_project1.png" alt="Launch" title="Launch"></p>
<h1><a id="Project_Layers_166"></a>Project Layers</h1>
<p>Once a project has been uploaded it will appear in the list of projects. When you click on it, the list of layers will be displayed. Layer <code>All</code> represent the whole project. You can either build or train whole project using <code>All</code> layer or each layer separately for debug purposes. The menu option for <code>All</code> layer is almost the same as each layer. Single layer has <code>Settings</code> options reflecting current settings of the layer taken from the configuration file. You can delete the whole project but cannot a selected layer. To do so, you need to upload the updated project from your local machine.<br>
On the picture below, you can see <code>project id</code> associated with the project. It is needed for REST API.</p>
<p><img src="http://www.zcymatix.com/img/layer_page1.png" alt="Layer menu" title="Launch"></p>
<p>NOTE! Launching all layer of the project separately, does not mean launching the whole project(!). As it was stated above, launching a layer is only for test purposes. You must launch All layer to engage all layers in a stack to run in production mode.</p>
<h1><a id="Project_ID_174"></a>Project ID</h1>
<p>By clicking on the project ID, you will see the REST API to use your project in production.<br>
<img src="http://www.zcymatix.com/img/rest_info.png" alt="Using project id" title="Launch"></p>
<h1><a id="Training_time_178"></a>Training time</h1>
<p>Depending on project complexity it may take from few seconds to few hours to train it. When project training/building is finished you will receive e-mail notification with the <strong><em>PROJECT ID</em></strong> required for <strong><em>project launch</em></strong> REST request. When training, projects or layers icon is blinking.</p>
<h1><a id="Project_WEB_UI_indicators_181"></a>Project WEB UI indicators</h1>
<p>Web interface has color coded icons against project and each layer.</p>
<p>RED - means that the project is NOT loaded</p>
<p>GREEN - means that the project has been loaded in production mode</p>
<p>YELLOW - indicates that one of the project layer has been loaded, but not the whole project</p>
<h1><a id="NLU_service_REST_API_190"></a>NLU service REST API</h1>
<h2><a id="Launch_request_191"></a>Launch request</h2>
<p>This is <code>very first</code> handshake request from client application when it is started for the first time. The goal is to allocate <code>session_id</code>, which must be stored by application and provided with all sequential requests afterwards, including <code>launch</code> request. <em>It is a key to the instance of the application.</em><br>
Example:<br>
<strong><em><a href="https://nlp2.zcymatix.com/?zcmd=launch&amp;project_id=f38360cd-08c5-482b-8c22-c2bc67194ab8">https://nlp2.zcymatix.com/?zcmd=launch&amp;project_id=f38360cd-08c5-482b-8c22-c2bc67194ab8</a></em></strong><br>
Parameters:</p>
<pre><code class="language-json">    cmd = launch
    project_id = f38360cd-08c5-482b-8c22-c2bc67194ab8
</code></pre>
<p>NOTE! <code>f38360cd-08c5-482b-8c22-c2bc67194ab8</code> is fake project id in this example.</p>
<p>On success, <code>msg</code> field will contain the <code>session_id</code>:</p>
<pre><code class="language-json">{ "<span class="hljs-attribute">code</span>": <span class="hljs-value"><span class="hljs-number">200</span></span>, "<span class="hljs-attribute">msg</span>": <span class="hljs-value"><span class="hljs-string">"2cb3b87d-e29c-4743-bab1-0fc5cb98db6d"</span> </span>}
</code></pre>
<p>Athentication error will be returned if incorrect:</p>
<pre><code class="language-json">{ "<span class="hljs-attribute">code</span>": <span class="hljs-value"><span class="hljs-number">101</span></span>, "<span class="hljs-attribute">msg</span>": <span class="hljs-value"><span class="hljs-string">"The user name or password is incorrect"</span> </span>}
</code></pre>
<p>When application starts next time, launch request must be submitted <strong>including previously obtained session id.</strong> It is important to access application instance data, stored in persistant memory of the application.</p>
<p><strong><em><a href="https://nlp2.zcymatix.com/?zcmd=launch&amp;project_id=f38360cd-08c5-482b-8c22-c2bc67194ab8&amp;session_id=2cb3b87d-e29c-4743-bab1-0fc5cb98db6d">https://nlp2.zcymatix.com/?zcmd=launch&amp;project_id=f38360cd-08c5-482b-8c22-c2bc67194ab8&amp;session_id=2cb3b87d-e29c-4743-bab1-0fc5cb98db6d</a></em></strong></p>
<p>Parameters:</p>
<pre><code class="language-json">    cmd = launch
    project_id = f38360cd-08c5-482b-8c22-c2bc67194ab8
    session_id = 2cb3b87d-e29c-4743-bab1-0fc5cb98db6d
</code></pre>
<p>Here is REST API flow diagram:<br>
<img src="http://www.zcymatix.com/img/REST_workflow.png" alt="REST API workflow" title="REST API workflow"></p>
<h2><a id="Inference_example_225"></a>Inference example</h2>
<p><strong><em><a href="https://nlp2.zcymatix.com/?zcmd=deduce&amp;session_id=2cb3b87d-e29c-4743-bab1-0fc5cb98db6d&amp;query=Hello+World">https://nlp2.zcymatix.com/?zcmd=deduce&amp;session_id=2cb3b87d-e29c-4743-bab1-0fc5cb98db6d&amp;query=Hello+World</a></em></strong><br>
Parameters:</p>
<pre><code class="language-json">    cmd = deduce
    session_id = 2cb3b87d-e29c-4743-bab1-0fc5cb98db6d
    query = hello world
</code></pre>
<p>The response:</p>
<pre><code class="language-json">{ "<span class="hljs-attribute">code</span>":<span class="hljs-value"><span class="hljs-number">201</span></span>, "<span class="hljs-attribute">msg</span>":<span class="hljs-value"><span class="hljs-string">"{"</span>t_intent<span class="hljs-string">":"</span>GREETINGS<span class="hljs-string">"}"</span></span>}
</code></pre>
<h2><a id="List_of_response_codes_239"></a>List of response codes</h2>
<pre><code>List of codes:
    200 - Session id is provided in msg field as a string
    201 - Inference is provided in msg field as a JSON string
    202 - Info is provided in msg field as a string
    102 - Project is loading
    101 - Authentication error
    100 - Invalid parameters
</code></pre>
<p>It may take few seconds for a project to be launched (if it was not before). If during this time clients inference request comes to the backend, it will respond with the code <code>102</code>. <strong><em>Client must repeat the request</em></strong> until the inference response comes back with the code <code>201</code>.<br>
This is the worst case scenario, because projects must be loaded in prediction mode for <code>production</code> use after training is finished, thus it should be always loaded.</p>
<h1><a id="train_section_253"></a><code>.train</code> section</h1>
<p>Alternative name is <strong><code>.user</code></strong> for readability.<br>
The section contains training samples. Formal syntax is:</p>
<pre><code>.train
    &lt;INTENT&gt;: &lt;utterance with or without slot labels&gt;
</code></pre>
<p>Note, the intent is optional. In this case the utterance may be used to slot fitting:</p>
<pre><code>.train
    I want pizza with (extra cheese){t_toppings} and ham{t_toppings}
</code></pre>
<p>The following example teaches to ingore the utterace all together:</p>
<pre><code>.train
    I am not sure what I want
</code></pre>
<p>This example is quite important to demonstrate the key concept, while building a training set. One thing can be descrided <code>what it is</code> and <code>what it is not</code>! Keeping this in mind, you can create more accurate training sets.</p>
<h1><a id="prompt_section_272"></a><code>.prompt</code> section</h1>
<p>Alternative name is <strong><code>.bot</code></strong> for readability.<br>
What if we want AI system to respond to user query? Lets use the Hello World code:</p>
<pre><code>.user
    GREETING: Hello World
.prompt
    GREETING: Hello my friend
    GREETING: Hello!
    GREETING: Hi!    
</code></pre>
<p>By adding section <strong><em>.prompt</em></strong> we can define user prompts:</p>
<pre><code>INTENT:&lt;PROMPT VARIANT&gt;
</code></pre>
<p>In the example above GREETING has three variants. They will be selected randomly in order to create more human like interaction. It reads like this - when user greets me reply this. Prompt text may contain slots/parameters values.</p>
<pre><code>.prompt
    NAVIGATE: Ok, I am starting navigation to {t_dest} by {t_car}
</code></pre>
<p>Where <strong><em>t_dest</em></strong> and <strong><em>t_car</em></strong> are slots/parameters.<br>
Prompts purpose is twofold 1. to be able to respond to user. 2. Prompt as a template with slot names to be passed to next layer in the inference pipeline. This mechanism is used in <code>expert systems</code> layers.<br>
The idea: You collect all the data from user in the form of slots and their values and then use prompt template to build the utterance for the next model.</p>
<pre><code class="language-json">.prompt
    R~READY: {t_param1} {t_param2} {t_param3}...
</code></pre>
<p>Please, be careful when having multiple layers in non expert system projects. Lets say you have three layer project. Second layer defines a prompt. In such cases <code>propmt is passed to third layer instead of utterance(!)</code></p>
<h1><a id="define_section_301"></a><code>.define</code> section</h1>
<p>Lets update <strong><em>hello.txt</em></strong> file a little. Add <strong><em>.define</em></strong> section.</p>
<pre><code class="language-json">.define
    @hi: Hello|hi
    @guys: guys|folks|World|
.train
    GREETING:@hi @guys
</code></pre>
<p>In this example we define two macros <strong><em>@hi</em></strong> and <strong><em>@guys</em></strong>. The resulting training set will be:</p>
<pre><code class="language-json">GREETING:hi folks
GREETING:hi World
GREETING:hi guys
GREETING:Hello folks
GREETING:Hello World
GREETING:Hello guys
GREETING:Hello
GREETING:hi
</code></pre>
<p>Please note the last OR in <strong><em>@guys</em></strong> definition reads like <strong><em>empty string</em></strong>. So, <strong>@guys</strong> it is either <strong><em>guys</em></strong> or <strong><em>folks</em></strong> or <strong><em>World</em></strong> or <strong><em>empty string</em></strong>. It is similar to regular expression, but limited at the words level only. Examples:</p>
<ul>
<li><strong><em>folk(s|)</em></strong> is INVALID</li>
<li><strong><em>(folk|folks)</em></strong> is VALID</li>
</ul>
<h1><a id="list_section_326"></a><code>.list</code> section</h1>
<p>This section is very much the same as define with different syntax:</p>
<pre><code>.list=&lt;define name&gt;
    item1
    item2
    ...
</code></pre>
<p>Example:</p>
<pre><code>.list=us_state
    Alabama
    Alaska
    Arizona
    Arkansas
    California
    ...
</code></pre>
<p>It is the same as:</p>
<pre><code>.define
    @us_state: Alabama|Alaska|Arizona|Arkansas|California|...
</code></pre>
<p>Imagine you want to train <code>named entity recognizer</code>. Usually you get the text file with the list of items. <code>.list</code> section lets you quickly transform text file into the training file by adding the section header to the top.</p>
<h1><a id="Slots_parameters_352"></a><code>Slots</code> (parameters)</h1>
<p>In the training set we can assign intent and mark/label words with slot names for each utterance.<br>
Training file:</p>
<pre><code class="language-json">.define
    @take: take|bring
    @me: me|us|them
.train
    NAVIGATE: @take @me to Seattle{t_dest} by car{t_transport}
.prompt
    NAVIGATE: Sure, I am starting navigation to {t_dest} by {t_transport}
</code></pre>
<p>The inference will look like:</p>
<pre><code class="language-json">{"<span class="hljs-attribute">t_intent</span>":<span class="hljs-value"><span class="hljs-string">"NAVIGATE"</span></span>, "<span class="hljs-attribute">t_dest</span>":<span class="hljs-value"><span class="hljs-string">"Seattle"</span></span>, "<span class="hljs-attribute">t_transport</span>":<span class="hljs-value"><span class="hljs-string">"car"</span></span>}
</code></pre>
<p>This way we infere the meaning of the utterance.</p>
<h1><a id="Introduction_to_Layers_371"></a>Introduction to Layers</h1>
<p><a href="http://www.zcymatix.com"><code>zCymatix</code></a> platform is using the concept of <strong><em>layers</em></strong>. Each layer could be responsible for inference of specific things. For example, in case of ordering pizza you may want to infere <strong><em>pizza toppings</em></strong> and <strong><em>pizza kinds</em></strong> in separation of the training set that will be using them. Why? Because there may be too many pizza kinds and toppings, meaning that final training data set will grow dramatically if we use each pizza kind and topping explicitly. Of course you can use <a href="#placement-slot-inference"><code>placement slot inference</code></a>, but it is up to developer to decide which way to go. So, it is advisable to have a layer that would be replacing specific pizza kind and topping with something like <strong><em>PIZZA_KIND</em></strong> and <strong><em>PIZZA_TOPPING</em></strong> labels. Layer after that, would use them instead of actual values. At the end of the inference cycle they will be resolved to the actual values. The following example starts with more complex configuration file with two layers. Once you have more than one layer you have to name each of them:</p>
<pre><code class="language-json">[
    {
        "<span class="hljs-attribute">layer_name</span>":<span class="hljs-value"><span class="hljs-string">"Pizza kinds"</span></span>,
        "<span class="hljs-attribute">data_files</span>":<span class="hljs-value">[<span class="hljs-string">"kinds"</span>, <span class="hljs-string">"macros.h"</span>]
    </span>},
    {
        "<span class="hljs-attribute">layer_name</span>":<span class="hljs-value"><span class="hljs-string">"Ordering pizza"</span></span>,
        "<span class="hljs-attribute">data_files</span>":<span class="hljs-value">[<span class="hljs-string">"order_pizza.txt"</span>, <span class="hljs-string">"macros.h"</span>]
    </span>}
]
</code></pre>
<p>Ill walk you through. First of all, lets put all the macros in one file <strong><em>macros.h</em></strong> and include it into both layers. It is optional however. So, lets look at <strong><em>kinds.txt</em></strong> file. One utterance in particular:</p>
<pre><code>I would like to place an order for a small BBQ chicken and large meat pizza
</code></pre>
<p>For simplicity sake, lets ignore pizza sizes inference.</p>
<p><strong><em>kinds.txt</em></strong>:</p>
<pre><code>.train
    I would like to place an order for a small (BBQ chicken){&amp;PIZZA_KIND} and \
    large meat{&amp;PIZZA_KIND} pizza
</code></pre>
<p><em>Intent is not present here, because the purpose of this utterance is to create <code>sufficient context</code> to isolate and extract pizza kind:</em><br>
<strong><em>PIZZA_KIND = BBQ chicken</em></strong><br>
<strong><em>PIZZA_KIND = meat</em></strong></p>
<p>This is a mechanism to label multiple words with specific <code>label</code> and using multiple instance of the label in a single utterance. To explain further, lets look at the next layer and file<br>
<strong><em>order_pizza.txt</em></strong>:</p>
<pre><code>.train
    ORDER_PIZZA: I would like to place an order for a small PIZZA_KIND{t_kind} and \
                 large PIZZA_KIND{t_kind} pizza
</code></pre>
<p>The intent <strong><em>ORDER_PIZZA</em></strong> present here, because the purpose of this layer is to get <strong><em>the intent and slots/parameters values</em></strong> that come with it.<br>
<strong><em>PIZZA_KIND{t_kind}</em></strong> marks both instances of the mentioned pizza kinds.<br>
The resulting inference after applying both layers will be:</p>
<pre><code class="language-json">{
    "<span class="hljs-attribute">t_utt</span>":<span class="hljs-value"><span class="hljs-string">"i would like to place an order for small BBQ chicken and large meat pizza"</span></span>,
    "<span class="hljs-attribute">t_intent</span>":<span class="hljs-value"><span class="hljs-string">"ORDER_PIZZA"</span></span>,
    "<span class="hljs-attribute">t_kind</span>":<span class="hljs-value">[<span class="hljs-string">"BBQ chicken"</span>, <span class="hljs-string">"meat"</span>]
</span>}
</code></pre>
<p>You could say - <strong><em>How about if I have a macro @pizza_kind and put all values there and use training utterance in one single layer?:</em></strong></p>
<pre><code>.define
    @pizza_kind: BBQ chicken|meat|Hawaiian|...
.train
    ORDER_PIZZA: i would like to place an order for small @pizza_kind{t_kind} and \
                 large @pizza_kind{t_kind} pizza
</code></pre>
<p>Of course you can! BUT, how many utterances will be produced? <strong><em>A LOT!!!</em></strong> Imagine if on top you have:</p>
<pre><code>.define 
    @i: i|we|they 
    @order: (place|) order for|get|buy
    @small: small|large|medium|
</code></pre>
<pre><code>ORDER_PIZZA: @i would like to @order @small @pizza_kind{t_kind} and \
             @pizza_kind{t_kind} pizza
</code></pre>
<p>So, this mechanism enables smaller context needed to train the layer to extract and label the pizza kinds. Look - do you need <strong><em>all</em></strong> words in the example utterance in layer Pizza kinds? Not really. So, I would put into training file something like this:</p>
<pre><code>.define 
    @pizza_kind: BBQ chicken|meat|pepperoni|Hawaiian
.train
    @small @pizza_kind{&amp;PIZZA_KIND} (and @pizza_kind{&amp;PIZZA_KIND} pizza|)
</code></pre>
<p>So, having a context consisting only surrounding words is enough? You decide. But be careful though. <strong><em>False positives one of the biggest issues in NLU systems</em></strong>, finding the balance between training time, number of utterances and sufficient context is not easy task to create <strong><em>high quality training set.</em></strong> <a href="http://www.zcymatix.com"><code>zCymatix</code></a> platform gives the tools to go either way.</p>
<h1><a id="Dialogs_445"></a>Dialogs</h1>
<p>There are two types of dialogs supported by the platform <strong><em>AI system asks questions</em></strong> and <strong><em>User asks questions</em></strong>. And third one is the combination of these two.</p>
<h2><a id="AI_system_asks_questions_447"></a>AI system asks questions</h2>
<p>This type of dialog assumes that AI system knows the set of slots/parameters to collect from user. <code>Presence of the slots values</code> is sufficient for the system to consider conversation complete.<br>
Lets take as example a visit to doctor.</p>
<pre><code>Patient&gt; I have a stomach ache
AI Doctor&gt; Did you take any medications?
Patient&gt; Yes
AI Doctor&gt; What kind of medication did you take?
Patient&gt;...
</code></pre>
<p>Or</p>
<pre><code>Patient&gt; I have a stomach ache
AI Doctor&gt; Did you take any medications?
Patient&gt; No
AI Doctor&gt; How bad is the pain on the scale of 1 to 10?
Patient&gt;...
</code></pre>
<p>As you can see based on the patient answer, conversation goes different routes.<br>
Using <code>toth</code> flags:</p>
<pre><code>    &quot;toth&quot;:True
    &quot;intent_to_utterance&quot;:true
</code></pre>
<p>or/and <code>prompts templates</code> we can follow <strong><code>train of thought</code></strong> of the conversation and use users intents and answers as a context for next inferences. Intents of the previous statements are embedded into next user utterances. It allows to have multiturn dialogs.</p>
<p>Another example: pizza assistant. User can freely provide the information about the pizza without following strict order of the conversation:</p>
<pre><code>    User&gt; I want to order some pizza
    Bot&gt; What kind would you like?
    User&gt; I want small BBQ chicken with extra cheese and tomatoes
    Bot&gt; What is the delivery address?
    User&gt;...
    Bot&gt; Here is you order... Should I go ahead and place your order?
    User&gt; you bet!
    Bot&gt; Great, thank you!!!
</code></pre>
<p>The conversation flow depends on already provided parameters and system would ask only those questions to retrieve missing parameters. So, the conversation could go like this:</p>
<pre><code>    User&gt; I want small BBQ chicken with extra cheese and tomatoes on top and my address is ...
    Bot&gt; Here is you order... Should I go ahead and place your order?
    User&gt; Yes
</code></pre>
<p>There are few things to know before we can create such dialog.</p>
<h3><a id="gate_section_492"></a><code>.gate</code> section</h3>
<p>Its purpose is to fullfil user query. .gate section contains a small script for generating new intent based on the inference history. The syntax uses python style <code>if</code> statements. It is better to demonstrate on <code>Pizza</code> example:</p>
<pre><code class="language-python">.gate
    <span class="hljs-string">'ASK_KIND'</span>        <span class="hljs-keyword">if</span> o.t_intent == <span class="hljs-string">'ORDER_PIZZA'</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> hasattr( o, <span class="hljs-string">'t_kind'</span> )
    <span class="hljs-string">'ASK_SIZE'</span>        <span class="hljs-keyword">if</span> o.t_intent == <span class="hljs-string">'ORDER_PIZZA'</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> hasattr( o, <span class="hljs-string">'t_size'</span> )
    <span class="hljs-string">'ASK_TOPPINGS'</span>    <span class="hljs-keyword">if</span> o.t_intent == <span class="hljs-string">'ORDER_PIZZA'</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> hasattr( o, <span class="hljs-string">'t_toppings'</span> )
    <span class="hljs-string">'ASK_ADDRESS'</span>     <span class="hljs-keyword">if</span> o.t_intent == <span class="hljs-string">'ORDER_PIZZA'</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> hasattr( o, <span class="hljs-string">'t_address'</span> )
    <span class="hljs-string">'ASK_TO_CONFIRM'</span>  <span class="hljs-keyword">if</span> o.t_intent == <span class="hljs-string">'ORDER_PIZZA'</span>
    <span class="hljs-string">'R~THANKS_YES'</span>    <span class="hljs-keyword">if</span> o.t_intent == <span class="hljs-string">'ORDER_PIZZA_YES'</span>
    <span class="hljs-string">'R~THANKS_NO'</span>     <span class="hljs-keyword">if</span> o.t_intent == <span class="hljs-string">'ORDER_PIZZA_NO'</span>
</code></pre>
<pre><code>.prompt
    ASK_KIND: What kind of pizza would you like?(BBQ chicken, Hawaiian, pepperoni, etc)
    ASK_SIZE: What size? (large, medium, small, etc)
    ASK_TOPPINGS: Anything on top?(ham, cheese, tomatoes, etc)
    ASK_ADDRESS: What is your address?
    ASK_TO_CONFIRM: Your order is {t_size} {t_kind} pizza with {t_topping} \
                     to be delivered to {t_address} Should I go ahead and place the order?
    R~THANKS_YES: Thank you for your order
    R~THANKS_NO: Sure, I will cancel the order for you
</code></pre>
<p>The intuition is simple. It reads like this - when current intent is ORDER_PIZZA and we still dont know pizza kind - generate intent ASK_KIND to ask user about pizza kind. The actual question is in the <code>prompt</code> section.<br>
<strong><em>ORDER of gates IS important!!!</em></strong> Gates are applied in the same order listed in the section.<br>
<strong>Please note a mandatory prefix o. in front of slot and intent label and also single quotes surrounding the intent name.</strong><br>
Gates are executed in the sequential order and they must be <code>mutually exclusive</code>. The sequence of the gates execution stops when first one returns not empty intent.<br>
Be aware of the following case. It WILL cause a break in the model, because the return value will be always either <code>INTENT_2</code> or <code>INTENT_3</code>.</p>
<pre><code>.gate
    // ERROR!!!
    'INTENT_2' if o.t_intent == 'INTENT_1' and not hasattr( o, 't_something' ) else 'INTENT_3'
</code></pre>
<p>Ignore for now prefix <strong><em>R~</em></strong> of the <strong><em>R~THANKS_YES</em></strong> and <strong><em>R~THANKS_NO</em></strong>. It has special meaning to be discussed <a href="#r-prefix">later</a>.<br>
It was mentioned earlier that <strong><em>prompts template</em></strong> can be used to pass information to the next layer. That would eliminate the need to have scripted <strong><em>.gate</em></strong>. In each particular case developer has to make their judgement call which way to go. Note, though, gates do not require training.<br>
Consider another example:</p>
<pre><code>.gate
    'ASK_CITY' if o.t_intent == 'Q42' and not hasattr( o, 't_city' )
</code></pre>
<p>Keeping in mind that the goal of the gate is to potentially change the intent, the gate above checks if current intent is <code>Q42</code>, but the t_city was not provided, return intent which would tell user something like: You did not provide the city. You can argue the rational of this, saying why cant I just train it in such way, so when city is provided one intent is produced and if not provided - another one? Absolutely true. However, we want to keep the options open for developer. Not to mention, that the gate mechanism does not require training.<br>
NOTE! Order of the gates is important, if gate execution depends on previous gate outcome.</p>
<h2><a id="User_asks_questions_535"></a>User asks questions</h2>
<p>The best example of such dialog would be Frequetly Asked Questions of a website. Again toth mechanism allows following handling questions differently depending on the context. Example of our web service:</p>
<pre><code>User&gt; What can you do for me?
Service&gt; I am a Natural Language Understanding platform and I can help you to create AI assistants
User&gt; How?
Service&gt; First, you need to create a project
User&gt; How?
Service&gt; Minimalistic project consists of two files - configuration file and training file
</code></pre>
<p>Training file:</p>
<pre><code>.train
    I~INTRO: what can you do for me
    I~INTRO: what is your (purpose|goal|task|agenda)
    I~INTRO: how you can help me
    I~INTRO: how can you help me
    I~INTRO: &lt;...&gt;
    
    DO_CREATE_PROJECT: I~INTRO how?
    DO_CREATE_PROJECT: I~INTRO how is that?
    DO_CREATE_PROJECT: I~INTRO how can I do that?
    DO_CREATE_PROJECT: I~INTRO what should I do?
    DO_CREATE_PROJECT: I~INTRO any guidance (please|)?
    DO_CREATE_PROJECT: &lt;...&gt;
    
    MIN_PROJECT: DO_CREATE_PROJECT how?
    MIN_PROJECT: DO_CREATE_PROJECT how is that?
    MIN_PROJECT: DO_CREATE_PROJECT how can I do that?
    MIN_PROJECT: DO_CREATE_PROJECT any guidance (please|)?
    MIN_PROJECT: &lt;...&gt;
.prompt
    I~INTRO: I am a Natural Language Understanding platform and I can help you to create AI assistants
    DO_CREATE_PROJECT: First, you need to create a project
    MIN_PROJECT: Minimalistic project consists of two files - configuration file and training file
</code></pre>
<p>As you can see here, the same question How? gives contextual adequate response. Also see <a href="#How_to_control_inference_history_939">how to control inference history</a> section for intent prefixes.</p>
<h1><a id="regex_section_574"></a><code>.regex</code> section</h1>
<h2><a id="Replacement_575"></a>Replacement</h2>
<pre><code>.regex
    &amp;and:\b(?:as well as|and also)\b
</code></pre>
<p>It is a direct replacement of words in the utterance to simplify training sets. You can use the section to prevent your training set to be extremely large. Please note, there should be one and only one group - <code>0</code>, full match. To achive that use non-capturing groups - (?:regex). As in the example above, matching group <code>0</code> equals either: as well as or and also. Refer  <a href="https://www.regular-expressions.info/refcapture.html">here</a> for details.</p>
<p>More complex example:</p>
<pre><code>.regex
    &amp;1 hours and 30 minutes : \bone\s+(?:and|\&amp;)\s+(?:(?:a|the)\s+)?half\s+(?:an?\s+)?h(?:ou)?r?s?\b
</code></pre>
<h2><a id="Lookup_lables_588"></a>Lookup lables</h2>
<pre><code>.regex
    P_SIZE:\b(?:small|medium|large)\b
</code></pre>
<p>The actual value of <code>small</code>, <code>medium</code> or <code>large</code> is replaced by <code>P_SIZE</code> and passed to the NN layer so that we have less training samples. At the last layer of the model, the values will be restored. See <a href="#pizza2-bot-example">pizza2 example</a> for more details.<br>
<code>IMPORTANT!</code> There must be one group infered by the regular expression(!)</p>
<h1><a id="Prompt_label_596"></a>Prompt label</h1>
<p>Prompt is a powerful tool of <strong><em>ToTh</em></strong> mechanism to control passing information from one inference layer to another. It could be a simple text response corresponding to user query or a <strong><em>template which uses collected slot and their values</em></strong> to build next utterance for next layer in the pipeline, <strong>IF desired</strong>. Must reiterate this point. Very first inference layer gets user query. The output is either updated utterance or a prompt, which becomes an input to next layer and so on.</p>
<pre><code>utterance =&gt; 
    Layer1 =&gt; 
        updated utterance OR prompt =&gt; 
            Layer2 =&gt; ... 
                final Layer =&gt; prompt
</code></pre>
<p><strong>Note! If layer produces a prompt, it is used as an input for the next layer, unless of course layer is final. In that case prompt is what is presented to user as a response to user query.</strong><br>
Example:</p>
<pre><code>Utterance: Take me to Seattle =&gt; 
    [Address Layer] =&gt; 
        Utterance: Take me to P_PLACE =&gt; 
            [Intent layer] =&gt; 
                prompt:Sure, I will nagivate you to {t_dest}
                {
                    't_intent':NAVIGATE
                    't_dest':Seattle
                    't_prompt':Sure, I will navigate you to Seattle
                }
</code></pre>
<p>The values in the template are controlled by prompts prefixes as described below:</p>
<h2><a id="Prefix______621"></a>Prefix <strong>#</strong></h2>
<p>Implies using labels <strong><em>name</em></strong> in the <strong><em>most recent inference</em></strong>. <strong><em>NOTE: if value is absent it will be replaced with None</em></strong></p>
<pre><code>Example: t_name value is in the last inference, t_age is absent
.prompt
    RESULT: {#t_name} {#t_age}
    # The value of RESULT: t_name None
</code></pre>
<h2><a id="Prefix______630"></a>Prefix <strong>?#</strong></h2>
<p>Implies using labels <strong><em>name</em></strong> in the <strong><em>most recent inference</em></strong>. <strong><em>NOTE: if value is absent it will be skipped from the prompt</em></strong></p>
<pre><code>Example:  t_name value is in the last inference, t_age is absent
.prompt
    RESULT: {?#t_name} {?#t_age}
    # The value of RESULT: t_name 
</code></pre>
<h2><a id="Prefix______639"></a>Prefix <strong>$</strong></h2>
<p>Implies using labels <strong><em>name</em></strong> in <strong><em>whole inference history</em></strong>. The approach can be used as an input for dialog tracking layers. <strong><em>NOTE: if value is absent it will be replaced with None</em></strong></p>
<pre><code>Example: t_name value is in all whole history, t_age is absent
.prompt
    RESULT: {$t_name} {$t_age}
    # The value of RESULT: t_name None
</code></pre>
<h2><a id="Prefix______648"></a>Prefix <strong>?$</strong></h2>
<p>Implies using labels <strong><em>name</em></strong> in <strong><em>whole inference history</em></strong>. <strong><em>NOTE: if value is absent it will be skipped from the prompt</em></strong></p>
<pre><code>Example: t_name value is in all whole history, t_age is absent
.prompt
    RESULT: {?$t_name} {?$t_age}
    # The value of RESULT: t_name 
</code></pre>
<h2><a id="Prefix______657"></a>Prefix <strong>.</strong></h2>
<p>Implies using labels <strong><em>value</em></strong> in the <strong><em>most recent inference</em></strong>. <strong><em>NOTE: if value is absent it will be replaced with None</em></strong></p>
<pre><code>Example: t_name = John is in the last inference. 
.prompt
    GREETING: Hello {.t_name} =&gt; Hello John
</code></pre>
<h2><a id="Prefix______665"></a>Prefix <strong>?.</strong></h2>
<p>Implies using labels <strong><em>value</em></strong> in the <strong><em>most recent inference</em></strong>. <strong><em>NOTE: if value is absent it will be skipped from the prompt</em></strong></p>
<pre><code>Example: t_name is absent in the last inference. 
.prompt
    GREETING: Hello {?.t_name} =&gt; Hello
</code></pre>
<h2><a id="Empty_label_prefix_673"></a>Empty label prefix</h2>
<p>Implies using labels <strong><em>values</em></strong> in <strong><em>whole inference history</em></strong>. <strong><em>NOTE: if value is absent it will be replaced with None</em></strong></p>
<pre><code>Example: t_kind values are in whole inference history, t_kind = BBQ and t_kind = meat
.prompt
    ORDER_PIZZA: Ok, I will place an order of {t_kind} pizza for you =&gt; 
    =&gt; Ok, I will place an order of BBQ, meat pizza for you
</code></pre>
<h2><a id="Prefix______682"></a>Prefix <strong>?</strong></h2>
<p>Implies using labels <strong><em>values</em></strong> in <strong><em>whole inference history</em></strong>. <strong><em>NOTE: if value is absent it will be skipped from the prompt</em></strong></p>
<pre><code>Example: t_name is absent in inference history
.prompt
    GREETING: Hello {?t_name} =&gt; Hello
</code></pre>
<h2><a id="Prompt_label_value_access_by_index_690"></a>Prompt label value access by index</h2>
<p>While building a prompt, the label value can be accessed by index in the inference history, like so: <code>{t_utt-1}</code>. Index <code>-1</code> refers value of the label <code>t_utt</code> of in the previous inference.<br>
If previous inference is not available, <code>None</code> value is used in the prompt. If you want the value to be omitted in such case, use <code>{?t_utt-1}</code>.</p>
<pre><code>Example: 
.train
    ASKING_AGE: how old are you
    R~RESP_YES: ASKING_AGE (yes|sure|of course)
    R~RESP_NO: ASKING_AGE (no|nope|don't care)
.prompt
    ASKING_AGE: I don't know answer to the question, would you like to forward it to my parents?
    R~RESP_YES: Sure. I am forwarding your question {t_utt-1} to my parents
    R~RESP_NO: Ok, no problem.
</code></pre>
<p>Side note: this particular example relies on <code>flag</code> toth to be enabled</p>
<h1><a id="PIZZA2_BOT_Example_707"></a>PIZZA2 BOT Example</h1>
<p>Lets consider PIZZA2 BOT example. In this example we will not use scripting part utilizing only <strong><em>Neural Networks(NN)</em></strong> layers. By no means it should be considered completed, however it showcases many useful features of the platform. The project has 3 layers.</p>
<h2><a id="Layer_1_Slots_709"></a>Layer 1 Slots</h2>
<p>Layer 1 is named slots is dedicated to isolate types of the slots - <strong>pizza kind</strong>, <strong>pizza toppings</strong>,  <strong>size</strong> and <strong>delivery address</strong>. Here is the configuration for the layer:</p>
<pre><code class="language-json">{
    "<span class="hljs-attribute">layer_name</span>":<span class="hljs-value"><span class="hljs-string">"slots"</span></span>,
    "<span class="hljs-attribute">data_files</span>":<span class="hljs-value">[ <span class="hljs-string">"base.h"</span>,<span class="hljs-string">"slots.txt"</span> ]</span>,
    "<span class="hljs-attribute">bi_lstm</span>":<span class="hljs-value"><span class="hljs-literal">true</span></span>,
    "<span class="hljs-attribute">toth</span>":<span class="hljs-value"><span class="hljs-literal">true</span>
</span>}
</code></pre>
<p>It contains 2 files - <strong><em>base.h</em></strong> with useful macros, <strong><em>slots.txt</em></strong> is an actual training file.<br>
Lets discuss bi_lstm parameter.</p>
<pre><code class="language-json">"bi_lstm":true
</code></pre>
<p>Consider sentence: I would like cheese on top. It is clear that cheese refers to the toppings not the pizza type. We get it only when we see on top which comes at the end of the sentence. <strong><em>bi_lstm</em></strong> tells framework to read utterances not only <strong><em>left to right</em></strong> but also <strong><em>right to left</em></strong> to get this information.</p>
<p><code>&quot;toth&quot;:true</code> will be discussed later</p>
<p><strong>slots.txt</strong> file:</p>
<pre><code>.regex
    // Replace and leave it as such
    &amp;and:\b(?:as well as|and also)\b
    // Replace, but finally resolve to actual value
    P_SIZE: (?:@small)
.train
    // The goal is to isolate slot types(!) and replace them by the type name, so next layer - has
    // less samples to be trained with
    (ORDER_PIZZA|) @kind{&amp;P_KIND}
    (ORDER_PIZZA|) @toppings{&amp;P_TOPPINGS} on top
    (ORDER_PIZZA|) @i @want (P_SIZE|) @kind{&amp;P_KIND} @pizza (with|)
    (ORDER_PIZZA|) @i @want @kind{&amp;P_KIND} @and @kind{&amp;P_KIND} @pizza (with|)
    (ORDER_PIZZA|) @i @want @extra @toppings{&amp;P_TOPPINGS} on top
    (ORDER_PIZZA|) @i @want @extra @toppings{&amp;P_TOPPINGS} @and @extra @toppings{&amp;P_TOPPINGS} on top
    (ORDER_PIZZA|) @i @want @pizza with @extra @toppings{&amp;P_TOPPINGS}
    (ORDER_PIZZA|) on top @i @want @extra @toppings{&amp;P_TOPPINGS}
    (ORDER_PIZZA|) add (topping|toppings) @extra @toppings{&amp;P_TOPPINGS}
    (ORDER_PIZZA|) add @toppings{&amp;P_TOPPINGS} on top
    (ORDER_PIZZA|) (my|@the) address is @address{&amp;P_ADDRESS}
    (ORDER_PIZZA|) @i live in @address{&amp;P_ADDRESS}
</code></pre>
<p>It is not always makes sense to use trainable models in all layers. Sometimes it is sufficient to use direct replacement mechanism like regular expressions. <strong>You can, but you dont have to.</strong><br>
Developers of knowledge domains are faced with the challenge to come up with as many variations of utterances as possible, so the system can understand all users - the ways they talk. From one side - we want to have lots of utterances to achieve that, but on the other hand it leads to longer training times.</p>
<pre><code>.define
    @and: and|also|as well as
.train
    I would like ham @and extra cheese on top 
</code></pre>
<p>In the example above we would have 3 utterances instead of one because we have 3 variants for <code>and</code><br>
Lets review regex section.</p>
<pre><code>.define 
    @small: small|medium|large
.regex
    // Prefix &amp; is to indicate simple replacement
    // Ex utterance:  
    // 'I want bbq pizza as well as hawaiian' =&gt; 'I want bbq pizza and hawaiian'
    &amp;and: (?:as well as|and also)
    // Lookup label replacement
    // Replace all values of @small definition by P_SIZE.
    // At the end of inference it will be replaced by its origial value.
    // P_SIZE will be used for training instead of all values of @small
    P_SIZE: (?:@small)
</code></pre>
<p><code>&amp;and:(as well as|and also)</code> == to replace <code>as well as</code> and <code>and also</code> with <code>and</code>. Prefix &amp; tells that no need to resolve <code>and</code> to actual values it replaces in the final inference.<br>
<code>P_SIZE:@small</code>  == to replace <code>small</code>, <code>medium</code> or <code>large</code> with the type  <code>P_SIZE</code>, which must be resolved to its value in the final inference result.<br>
<strong><em>NOTE!</em></strong> Regex section is used for both - <strong>training</strong> and <strong>prediction</strong> modes.<br>
<strong><em>NOTE!</em></strong> Be careful if your knowledge domain contains names of <strong>movies</strong>, <strong>places</strong>, <strong>songs</strong> etc. In this case it could backfire at you, because you dont want to modify those names. Consider creation of separate layers that would isolate such names into types like <strong>P_MOVIE_NAME</strong>, <strong>P_SONG_NAME</strong>, etc. so next layer that supposed to infere user intents would not deal with them.<br>
<strong>base.h</strong> file:</p>
<pre><code>.define
    @i: i|we
    @i_want: @i @want
    @pizza: pizza
    @please: please|kindly
    @want: want|need|would like
    @and: and|and also|as well as
    @small: small|large|medium
    @kind: pepperoni|meat|Hawaiian|BBQ|meat|cheese
    @toppings: ham|cheese|tomato|meat|cheese
    @address: seattle|vancouver
    @extra: extra|
    @the: the|a|
    @yes: yes|sure|go ahead|you bet|sure why not
    @no: no|no way|nope|(@i|) changed my mind
</code></pre>
<p>Original utterance transformation with SLOTS layer:</p>
<pre><code>I would like to place an order for small pepperoni with extra cheese and ham on top
=&gt;
I would like to place an order for P_SIZE P_KIND with extra P_TOPPINGS and P_TOPPINGS on top
</code></pre>
<p>Latter is an input utterance to next layer called Pizza</p>
<h2><a id="Layer_2_Pizza_807"></a>Layer 2 Pizza</h2>
<p>Config for this layer:</p>
<pre><code class="language-json">{
    "<span class="hljs-attribute">layer_name</span>":<span class="hljs-value"><span class="hljs-string">"pizza"</span></span>,
    "<span class="hljs-attribute">data_files</span>":<span class="hljs-value">[<span class="hljs-string">"base.h"</span>,<span class="hljs-string">"pizza.txt"</span>]</span>,
    "<span class="hljs-attribute">bi_lstm</span>":<span class="hljs-value"><span class="hljs-literal">true</span></span>,
    "<span class="hljs-attribute">toth</span>":<span class="hljs-value"><span class="hljs-literal">true</span>
</span>}
</code></pre>
<p><strong>pizza.txt</strong> file:</p>
<pre><code>.train
    ORDER_PIZZA: @i @want some @pizza @please
    ORDER_PIZZA: @pizza (@please|)
    ORDER_PIZZA: ASK_SIZE P_SIZE{t_size}
    ORDER_PIZZA: ASK_KIND P_KIND{t_kind}
    ORDER_PIZZA: ASK_KIND P_KIND{t_kind} and P_KIND{t_kind}
    ORDER_PIZZA: ASK_TOPPINGS with P_TOPPINGS{t_toppings}
    ORDER_PIZZA: ASK_TOPPINGS with P_TOPPINGS{t_toppings} and P_TOPPINGS{t_toppings}
    ORDER_PIZZA: ASK_TOPPINGS P_TOPPINGS{t_toppings} on top
    ORDER_PIZZA: ASK_TOPPINGS P_TOPPINGS{t_toppings} and P_TOPPINGS{t_toppings} on top
    ORDER_PIZZA: ASK_ADDRESS P_ADDRESS{t_address}
    ORDER_PIZZA: ASK_ADDRESS @i live in P_ADDRESS{t_address}
    R~ORDER_PIZZA_YES: ASK_TO_CONFIRM @yes
    R~ORDER_PIZZA_NO: ASK_TO_CONFIRM @no
.prompt
    // Generate Prompt that contains only one(!) missing slot to train next dialog layer
    // With the prompt definition below one of:
    //   if t_kind is missing
    //   if t_size is missing
    //   if t_toppings is missing
    //   if t_address is missing
    //   if none is missing
    // will be passed to the next layer, which must be trained like this:
    // .train
    //   ASK_KIND: if t_kind is missing
    // See bot.txt file.
    ORDER_PIZZA: if {$!t_kind|t_size|t_toppings|t_address|none} is missing
    // NOTE! Prefix R~(==return) is an instruction to collect all slots values and clean up
    // the inference history, thus to forget what user said before.
    R~ORDER_PIZZA_YES: Thank you for you order :)
    R~ORDER_PIZZA_NO: Sure, may be next time
</code></pre>
<p>Now time to discuss:</p>
<pre><code>&quot;toth&quot;:true
</code></pre>
<p>It tells that the layer wants to receive <strong><em>last intent</em></strong> as a prefix to the input utterance. This is the essence of <strong>ToTh</strong> mechanism to communicate contextual information to make inferences more accurate. <strong>NOTE!</strong> Intents can be generated by any layer in the stack and be passed to the next layer with <code>toth</code> set to <code>true</code>. Otherwise, current utterance or prompt value is passed to the next layer unchanged. Consider the following training utterance:</p>
<pre><code>.train
    ORDER_PIZZA: ASK_TOPPINGS I want pizza with P_TOPPINGS{t_toppings}
</code></pre>
<p>It reads like this: when user is prompted to provide pizza toppings(previous intent was <strong><em>ASK_TOPPINGS</em></strong>) and user response is I want pizza with cheese, produce <strong><em>ORDER_PIZZA</em></strong> intent and assign <strong><em>t_toppings</em></strong> with its value. <code>t_toppings = cheese</code></p>
<p>Layer Pizza should contain as many utterances as possible to understand any user and the way they talk! The layer collects all slots and their values.<br>
Now, what is next? Next - is to figure out which question we need to ask. To do so we need to generate prompts, not utterances, because next layer inference is based on the fact which slots we have already collected. This information is stored in the inference history, which is what user said before. See the comments in prompt section above.</p>
<pre><code>.prompt
    ORDER_PIZZA: if {$!t_kind|t_size|t_toppings|t_address|none} is missing
</code></pre>
<p><code>{$!t_kind|t_size|t_toppings|t_address|none}</code> means look through all inference history and put <strong>slot names</strong>(prefix <strong>$</strong>) which are <strong>NOT</strong> present in the inference history(prefix <strong>!</strong>). Last value in the statement is dummy slot name None. It is used for readability purpose only as well as if and is missing. So the prompts template could just look like this:</p>
<pre><code>.prompt
    ORDER_PIZZA: {$!t_kind|t_size|t_toppings|t_address|none}
</code></pre>
<p>This way we build prompts providing sufficient information to the next layer to decide - what to ask next.<br>
Layer Pizza generates prompts =&gt; utterances for next layer:</p>
<pre><code>if t_size is missing
if t_kind is missing
if t_toppings is missing
if t_address is missing
</code></pre>
<p>Next layer is called Bot.</p>
<h2><a id="Layer_3_Bot_886"></a>Layer 3 Bot</h2>
<p>Configuration:</p>
<pre><code class="language-json">    {
        "<span class="hljs-attribute">layer_name</span>":<span class="hljs-value"><span class="hljs-string">"bot"</span></span>,
        "<span class="hljs-attribute">data_files</span>":<span class="hljs-value"><span class="hljs-string">"bot.txt"</span>
    </span>}
</code></pre>
<p><strong>bot.txt</strong> training file is very simple and contains very few utterances, which are, in fact, prompts generated by previous layer.</p>
<pre><code>.train
    ASK_KIND: if t_kind is missing
    ASK_SIZE: if t_size is missing
    ASK_TOPPINGS: if t_toppings is missing
    ASK_ADDRESS: if t_address is missing
    ASK_TO_CONFIRM: if None is missing
.prompt
    ASK_KIND: What kind of pizza would you like. For example, Hawaiian, BBQ, etc.?
    ASK_SIZE: Small, medium or large?
    ASK_TOPPINGS: What do you want on top. For example: tomato, ham, cheese, etc.?
    ASK_ADDRESS: What is delivery address?
    ASK_TO_CONFIRM: Your order is {?t_cnt} {t_size} {t_kind} pizza with {t_toppings} to \
                     be delivered to {t_address}. Would you like to go ahead with the order?
</code></pre>
<p>The training set for Bot layer is self-explanatory. Generate <strong><em>ASK_KIND</em></strong> prompt to user if <strong><em>t_kind</em></strong> slot is missing and so on. Valid question at this point is: Do I need to create training layer for such simple task? The answer is NO. Alternatively, you can use <a href="#gate-section-script">.gate</a> section described before to script the same logic, thus skipping training altogether for this type of inference.</p>
<h2><a id="Pizza_project_Final_Inference_912"></a>Pizza project Final Inference</h2>
<p>Lets review utterance transformation going though all layers of the Pizza2 project:</p>
<pre><code>// 'Slot' layer
I would like to place an order for small pepperoni with extra cheese and ham on top
where P_SIZE = small, P_KIND = pepperoni, P_TOPPINGS = cheese P_TOPPINGS = ham
=&gt;
// 'Pizza' layer
I would like to place an order for P_SIZE P_KIND with extra P_TOPPINGS and P_TOPPINGS on top
where t_size = small, t_kind = pepperoni, t_toppings = cheese t_toppings = ham
=&gt;
// 'Bot' layer
if t_address is missing
=&gt;
// Prompt to user
What is the delivery address?
</code></pre>
<p>I hope it is clear why the 1st question is What is the delivery address. It is because user already provided <strong><em>t_kind</em></strong>, <strong><em>t_toppings</em></strong> and <strong><em>t_size</em></strong> in the original sentence.</p>
<h1><a id="Inference_history_932"></a>Inference history</h1>
<p>This information is useful to understand platform operation under the hood. Inference history could be simply described as the things user said before. All inferences are collected in the <code>history</code> or <code>stack</code>. Those terms will be used interchangeably. The inference history contains:</p>
<ul>
<li>Layers input utterance with predefined slot name <code>t_utt</code></li>
<li>Layers intent with predefined slot name <code>t_intent</code>, if any</li>
<li>Layers infered <code>slots</code> and their <code>values</code>, if any</li>
<li>Layers prompt with predefined slot name <code>t_prompt</code>, if any</li>
</ul>
<h1><a id="How_to_control_inference_history_939"></a>How to control inference history</h1>
<p>At some point we need to collect all slots values in the stack to build an aggregative inference (pizza order), or may be forget whole inference, because it is self-contained and there is no need to remember it, or go one or more steps back in history when user says What? or Could you repeat it?. Or what if user changed their mind and wants to change the value of a slot? All of above are pieces of <strong>ToTh</strong> technology. It is done via intent prefixes:</p>
<ul>
<li>
<h2><a id="Intent_Prefixes_942"></a>Intent Prefixes</h2>
</li>
</ul>
<pre><code>&lt;no prefix&gt; - Normal intent. The intent and slots values to be collected in the history
R~ - Return all collected slots values in the inference history and clean the history. &quot;Return&quot; command.
F~ - Do not remember this particular inference in the history - &quot;Infere and forget&quot; command.
P~ - One step back command. 'Can you repeat it please?'
B~ - Two steps back command. 'What did you say before that?'
C~ - Change value of a slot. &quot;Change&quot; command.
X~ - Clean previous inference history and do not save current inference in it.
I~ - Clean previous inference history and save current inference in it. 'Tertis' game effect.
?? - We are open to discuss any other prefixes to control the history.
</code></pre>
<ul>
<li>
<h2><a id="Empty_prefix_954"></a><code>Empty</code> prefix</h2>
</li>
</ul>
<p>Intent without prefix with infered slots and their values are saved in the inference history.<br>
<code>ORDER_PIZZA: @i @want some @pizza @please</code><br>
where<br>
<code>t_intent = ORDER_PIZZA</code> will be kelp in stack until <code>R~</code> or <code>X~</code> session-based conversation intent comes along to erase it.</p>
<ul>
<li>
<h2><a id="R_prefix_Return_command_960"></a><code>R~</code> prefix. Return command</h2>
</li>
</ul>
<p>In Pizza layer we have:</p>
<pre><code>.train
    R~ORDER_PIZZA_YES: ASK_TO_CONFIRM @yes
    R~ORDER_PIZZA_NO: ASK_TO_CONFIRM @no
.prompt:
    R~ORDER_PIZZA_YES: Thank you for you order :)
    R~ORDER_PIZZA_NO: Sure, may be next time
</code></pre>
<p>Intents with <code>'R~'</code> prefix tell the framework to collect all slots and their values from history and return them to user as a inference in json format. After that inference history will be erased.</p>
<pre><code class="language-json">{
    "<span class="hljs-attribute">t_size</span>":<span class="hljs-value"><span class="hljs-string">"small"</span></span>, 
    "<span class="hljs-attribute">t_kind</span>":<span class="hljs-value"><span class="hljs-string">"pepperoni"</span></span>, 
    "<span class="hljs-attribute">t_toppings</span>": <span class="hljs-value">[<span class="hljs-string">"cheese"</span>, <span class="hljs-string">"ham"</span>]
</span>}
</code></pre>
<ul>
<li>
<h2><a id="F_prefix_Infere_and_Forget_command_978"></a><code>F~</code> prefix. Infere and Forget command</h2>
</li>
</ul>
<p>The prefix is used to prevent saving the inference in the history. For instance: <code>What time is it?</code> This is, most likely, self-contained statement and depending on the domain there may be no need to keep it in the history. So, the resulting inference will be returned, and it will not be remembered in the stack.</p>
<pre><code class="language-json">{
    "<span class="hljs-attribute">t_intent</span>":<span class="hljs-value"><span class="hljs-string">"GET_TIME"</span></span>,
    "<span class="hljs-attribute">t_prompt</span>":<span class="hljs-value"><span class="hljs-string">"It is 1:38PM"</span>
</span>}
</code></pre>
<p>This is actually tricky example. <a href="http://www.zcymatix.com"><code>zCymatix</code></a> platform does not act on user requests. It only inferes the intents and slots and follows the conversation flows. <code>t_prompt</code>'s time value above must be provided by the client application. The framework returns the prompt template from the training set: <code>&quot;It is {t_time}&quot;</code>, so user application should replace <code>t_time</code> with its value.</p>
<ul>
<li>
<h2><a id="P_prefix_One_step_back_command_988"></a><code>P~</code> prefix. One step back command</h2>
</li>
</ul>
<p>The prefix tells the framework to take last/previous inference in the history and return it. It is useful for cases when user asks, What did you say? Repeat please?.</p>
<pre><code>Bot&gt;What type of pizza would you like?
User&gt;What?
Bot&gt;What type of pizza would you like?
</code></pre>
<p>Please note, if previous intent was either R~ or I~ or X~, there will be no history records available. To have access  previous prompt always - consider training sample:</p>
<pre><code>.train
    F~REPEAT:what|what did you say|come again|repeat (please|)|pardon me
.prompt:
    F~REPEAT: *
</code></pre>
<p>Star <code>*</code> symbol tells to grab last value of the <code>t_prompt</code> in the history.</p>
<ul>
<li>
<h2><a id="B_prefix_Two_steps_back_command_1005"></a><code>B~</code> prefix. Two steps back command</h2>
</li>
</ul>
<p>The prefix tells the framework to take <code>top-1</code> inference from the history. It is useful for cases when user asks What did you say BEFORE that?</p>
<ul>
<li>
<h2><a id="C_prefix_Change_slot_value_command_1008"></a><code>C~</code> prefix. Change slot value command</h2>
</li>
</ul>
<p>The prefix tells the framework to change the value of the slot in the history<br>
<code>User&gt; Take me to Seattle</code></p>
<pre><code class="language-json">{
    "<span class="hljs-attribute">t_intent</span>":<span class="hljs-value"><span class="hljs-string">"NAVIGATE"</span></span>,
    "<span class="hljs-attribute">t_dest</span>":<span class="hljs-value"><span class="hljs-string">"Seattle"</span>
</span>}
</code></pre>
<p><code>User&gt; No, change it to Vancouver</code></p>
<pre><code class="language-json">{
    "<span class="hljs-attribute">t_intent</span>":<span class="hljs-value"><span class="hljs-string">"C~NAVIGATE"</span></span>,
    "<span class="hljs-attribute">t_dest</span>":<span class="hljs-value"><span class="hljs-string">"Vancouver"</span>
</span>}
</code></pre>
<p>The <code>t_dest</code> slot value <code>Seattle</code> will be replaced with <code>Vancouver</code> directly in the history.</p>
<ul>
<li>
<h2><a id="X_prefix_Clean_previous_history_command_1027"></a><code>X~</code> prefix. Clean previous history command</h2>
</li>
</ul>
<p>The prefix should be used if current inference suggests that the previous history must not be kept any longer. <strong><em>Current inference is not saved in the history.</em></strong></p>
<pre><code>.train
    CONFIRMATION:Would you like to proceed with your order?
    R~PLACE_ORDER: CONFIRMATION yes
    X~CANCEL_ORDER: CONFIRMATION no
.prompt
    USER_CONFUSED: I'm sorry
    // Collect all slots values in the collected history of the dialog and return to user
    R~PLACE_ORDER:Thank you for your order. Your order is {t_param1} {t_param2}...
    
    // Wipe out the history
    X~CANCEL_ORDER: Sure, I am canceling your order
</code></pre>
<p>Note, current inference slots, if any, will be returned to user in the inference.<br>
This prefix should be used for self-contained inference, meaning it has all information needed to make confident conclusion, plus no further inference should rely on it.</p>
<ul>
<li>
<h2><a id="I_prefix_Clean_previous_history_and_restart_command_1045"></a><code>I~</code> prefix. Clean previous history and restart command</h2>
</li>
</ul>
<p>The prefix should be used if current inference suggests that the previous history must not be kept any longer. <strong><em>Current inference is saved in the history.</em></strong> Think of this commands effect as Tertis effect.</p>
<h1><a id="Idioms_interpretation_Intent_prefix__1048"></a>Idioms interpretation. Intent prefix <code>~</code></h1>
<p>To support truly natural language understanding, we have a mechanism to interpret idioms and enable <code>slot filling</code> with semantic values <strong><em>not found in the original utterance</em></strong>. Here is an example:</p>
<pre><code>.train
    ~NAV: take me to a place where i can have a nice meal
    ~NAV_01: I am starving, walk me to a closest place where I can have a nice meal
.prompt:
    ~NAV: t_target=restaurant;t_prompt=Sure, I will take you to a {t_target};t_transport=car
    ~NAV_01: t_target=restaurant;t_prompt=Sure, I will take you to a {t_target};t_transport=walk
</code></pre>
<p>Prefix <code>~</code> must be first one in the intent. It <strong>can</strong> be used in combination with previously described prefixes. For example <code>~I~NAV</code>. It means that prompt contains additional slots. <code>I~</code> tells framework to restart collecting the history, while previous history will be lost. See <a href="#i-prefix-clean-previous-history-and-restart-command">above</a>.<br>
Please also note the separator <code>;</code> between slots-value pairs.</p>
<h1><a id="Remove_slot_value_from_inference_history_del_command_1062"></a>Remove slot value from inference history. <code>$del</code> command</h1>
<p>Lets say you want to delete a slot value from the history. Consider the example:</p>
<pre><code>.train
    C~PARKING_HS_MS: I want to park my car for 2{t_time_hour} hours and 15{t_time_min} minutes
    ~C_PARKING_HS: No, I want to park for 3{t_time_hour} hours
    ~C_PARKING_MS: No, I just want to be here for 5{t_time_min} minutes
.prompt:
    C~PARKING_HS_MS: Sure. {t_time_hour} hours and {t_time_min} minutes timer starts now.
    ~C_PARKING_HS: t_time_min = $del; t_prompt = Sure, {t_time_hour} hours timer start now.
    ~C_PARKING_MS: t_time_hour = $del; t_prompt = Sure, {t_time_min} minutes timer start now.
</code></pre>
<p>In this example user can change his/her mind as many time as desired, and slot values will be updated in history accordingly. Implicetly, ~C_PARKING_HS means that previous t_time_hour and t_time_min should be erased. We are explicitly chaning the value of t_time_hour and implicitly t_time_min.</p>
<h1><a id="Coreference_1076"></a>Coreference</h1>
<p>Consider the training samples using <code>P_PLACE</code> slot type:</p>
<pre><code>.train
    INT_SHOW_PLACE: show me P_PLACE{t_place} (on the map|)
    INT_SHOW_PLACE: where is P_PLACE{t_place}
    INT_SHOW_PLACE: I am looking for P_PLACE{t_place}
    INT_DISTANCE_INFO: how far is P_PLACE{t_dest}
    INT_NAVIGATE/t_place/t_dest:take me there
</code></pre>
<p>First four training samples rely on explicit place name we want to see or check the distance to. Last one has an intent and a list of slot names to look in the history to choose to resolve <code>it</code>:<br>
<code>INT_NAVIGATE/t_place/t_dest:take me there</code><br>
Why list of slots? The intuition is this - search for either <code>t_place</code> or <code>t_dest</code> in that order in the inference history and put its value to substitute <code>there</code>.<br>
<img src="http://www.zcymatix.com/img/session_memory_01.png" alt="Conventional &amp;quot;it&amp;quot;/&amp;quot;there&amp;quot; reolution" title="Conventional it/there reolution"><br>
As you can see, you have to collect inferences in client application and resolve the value of it. With zCymatix platform all done automatically on backend side.</p>
<p><img src="http://www.zcymatix.com/img/session_memory_02.png" alt="zCymatix &amp;quot;it&amp;quot;/&amp;quot;there&amp;quot; reolution" title="zCymatix it/there reolution"></p>
<h1><a id="Script_sections_1095"></a>Script sections</h1>
<p>To fulfill user queries zCymatix platform uses python script. By default, all inferences are returend to application as json objects. Application should parse them and act on user requests. Alternatevly, developers could keep the application focusing on its task and not deal with NLU aspects. Following project sections enable such functionality.</p>
<h2><a id="gate2_section_1098"></a><code>.gate2</code> section</h2>
<p>Its purpose is to fullfil user query. It contains python script executed AFTER inference is made, that is when intent and slot values are known. Important to remember the scope of exposed data.<br>
Object <code>o</code> as a Namespace object containing all inferences data from the collected history. Object <code>c</code> same as object <code>o</code>, but with current inference data only. NOTE! The following slot names are <strong>reserved</strong>:</p>
<p><strong><code>o.t_intent</code></strong> - is a string value of the current intent.</p>
<p><strong><code>o.t_prev_intent</code></strong> - is a string value of previous intent.</p>
<p><strong><code>o.t_prompt</code></strong> - is a list of previous prompts.</p>
<p>All other values of <strong>user</strong> defined the slots are lists(!). Example: <code>o.t_target = ['Seattle', 'Los Angeles'].</code><br>
So if you want to access the last value, do it like this:<br>
<code>o.t_target[ -1 ]</code></p>
<pre><code>.user
    WHAT_TIME: what time is it?
    .gate2
        if o.t_intent == 'F~TIME':
            o.t_cur_time = datetime( ).now( ).strftime( '%H:%M' )
        .bot
            F~TIME: It is {t_cur_time}
</code></pre>
<p>Set of sandboxed functions available below. <strong>In <code>.gate2</code> you can change, add, delete any slot from deduction history.</strong> Note! All the changes must be made in <code>o</code> object. Changes in <code>c</code> object will be ignored.<br>
<strong>NOTE!</strong> Order of the gates is important, if gate execution depends on previous gate(s) outcome.</p>
<h2><a id="script_section_1123"></a><code>.script</code> section</h2>
<p>Its purpose to define global python methods and shared, application wide, data within one layer. These methods are accessible from <code>.gate</code> and <code>.gate2</code> sections in runtime mode. Builtin set of functions is sandboxed and limited to:</p>
<pre><code>'hasattr', 'isinstance', 'len', 'vars', 'min', 'max', 'int', 'long', 'float', 'complex', 'list', 
'dict', 'str', 'unicode', 'tuple', 'set', 'False', 'True', 'None', 'oct', 'bin', 'bool', 'sorted'
'to_json', 'to_namespace', 'to_dict', 'read', 'write', 'datetime'
</code></pre>
<p>NOTE! Access to <code>datetime</code> must be done as a function. See example in <code>.gate2</code> section.</p>
<pre><code>datetime( ).now( ) # Correct
datetime.now( ) # Incorrect
</code></pre>
<p>Most of the functions are standard builtin. Custom methods and data exposed by plaform:</p>
<ul>
<li>To convert an object to a json string:</li>
</ul>
<p><strong><code>to_json( obj )</code></strong></p>
<ul>
<li>To convert dict to Namespace object:</li>
</ul>
<p><strong><code>to_namespace( obj )</code></strong></p>
<ul>
<li>Read from <strong>shared</strong> or <strong>private</strong> data storage. Private data storage is a persistant storage, associated with an <strong>instance of the application</strong></li>
</ul>
<p><strong><code>read( session_id, file_name, data_string, shared = True )</code></strong></p>
<ul>
<li>Write to <strong>shared</strong> or <strong>private</strong> data storage:</li>
</ul>
<p><strong><code>write( session_id, file_name, data_string, shared = True )</code></strong></p>
<ul>
<li>The <strong>local</strong> variable, <code>token/session_id</code>, that must be passed with <code>read</code> and <code>write</code> functions calls:</li>
</ul>
<p><strong><code>z_sid</code></strong></p>
<pre><code>Example:
        write( z_sid, 'my_file.json', to_json( my_app_obj ), shared = True )
</code></pre>
<p>Data structures declared in this sections should be treated as <code>shared data</code> of the application, which can be saved/retrived to/from persisant memory via available methods: <code>read</code> and <code>write</code></p>
<h2><a id="vars_section_1159"></a><code>.vars</code> section</h2>
<p>Its purpose to allocate variables declared in local context of python script.</p>
<h2><a id="slist_section_1162"></a><code>.slist</code> section</h2>
<p>The purpose is the same as <code>.list</code> section. In addition, global list variable in python environment is created. Example:</p>
<pre><code>.slist = allergy_type
    Eggs
    Milk
    Peanuts
    Tree nuts
    Fish
</code></pre>
<p>as a result global variable <strong><code>g_allergy_type</code></strong> is created in global context of python script making it visible from <code>.gate</code>, <code>.gate2</code> and <code>.script</code> sections. Please note <strong><code>g_</code></strong> prefix:</p>
<pre><code>g_allery_type = [
    'Eggs',
    'Milk',
    'Peanuts',
    'Tree nuts',
    'Fish'
]
</code></pre>
<h1><a id="Events_States_Sensors_Information_Embedding_1184"></a>Events, States, Sensors Information Embedding</h1>
<p>Contextual information embedding into utterances and prompts is the foundation of ToTh technology.<br>
Language operates by <code>symbols</code>. All words are the symbols, which are inherently indirect references to things that we can experience and understand. Keeping this in mind, we can <code>encode</code> any <code>contextual information</code> such as <code>events</code> or <code>states</code> or even <code>sensors information</code> using symbols, which we can use in the <code>training set</code> expanding our samples with those symbols.<br>
Lets review an example:</p>
<pre><code>I have my phone that controls multi room home music system via WiFi and 
I say: &quot;Play Def Leppard&quot;. It seems that it is self-contained and clear statement 
telling that I want to play music:) But there is a problem - where to play it? 
In which room? I did not say it explicitly. 
</code></pre>
<p>Going step by step, phone gets my intent:</p>
<pre><code class="language-json">{
    "<span class="hljs-attribute">t_intent</span>":<span class="hljs-value"><span class="hljs-string">"PLAY_MUSIC"</span></span>,
    "<span class="hljs-attribute">t_artist</span>":<span class="hljs-value"><span class="hljs-string">"Def Leppard"</span>
</span>}
</code></pre>
<p>now it needs to decide where to play the music or should we ask user? Sure, we may ask, but what if we take the challenge of figuring out automatically. Assuming that we have speakers <code>proximity sensor data</code> available on the phone - there are two ways to solve this. I said - <code>it needs to decide</code> meaning that the  <strong><code>phone</code></strong> having the intent and proximity info to the closest speaker(lets say it is <code>living room</code>) starts playing music there. Problem solved! Yes but. This is <code>not 'good'</code> solution and here is why:</p>
<ol>
<li>The decision is made by client device</li>
<li>The decision is based on hardcoded logic</li>
</ol>
<p>With <a href="http://www.zcymatix.com"><code>zCymatix</code></a> platform it is possible to encode and use sensors real-time data when I am in living room as symbol <code>__living_room__</code>:</p>
<pre><code>.train
    PLAY_MUSIC: __living_room__{t_location} play P_ARTIST{t_artist}
</code></pre>
<p>and the inference would be:</p>
<pre><code class="language-json">{
    "<span class="hljs-attribute">t_intent</span>":<span class="hljs-value"><span class="hljs-string">"PLAY_MUSIC"</span></span>,
    "<span class="hljs-attribute">t_artist</span>":<span class="hljs-value"><span class="hljs-string">"Def Leppard"</span></span>,
    "<span class="hljs-attribute">t_location</span>":<span class="hljs-value"><span class="hljs-string">"__living_room__"</span>
</span>}
</code></pre>
<p>So what? Here the advantages:</p>
<ol>
<li>
<p>Client device <code>did NOT make the decision</code> where to play the music, but merely provided encoded sensor information or in this case it is a state - where am I at the moment == <code>living room</code>.</p>
</li>
<li>
<p>This is <code>not hardcoded logic</code>, because the model which infered the intent and slots <code>resides on the backend</code> and can be trained or re-trained at any time, so there is no need to install new version of the application just because of some changes in logic.</p>
<p><strong>NOTE!</strong> You need to train your models with encoded events/states and modify user utterance in prediction mode.</p>
</li>
</ol>
<p>This makes client application <strong>cleaner, focusing on its task</strong> and <code>backend</code> takes care of the session, its history and the context. In our example my phone would only <strong><code>act</code></strong> on the intent by playing <code>Def Leppard</code> in <code>living room</code>.</p>
<h1><a id="Multiple_language_support_1226"></a>Multiple language support</h1>
<p>In order to support other languages besides English, all you have to do is to add lang field (ISO 639-1 and ISO alpha-2) into any of the layers of you project configurationISO:</p>
<pre><code>[
    {
        &quot;data_files&quot;:&lt;...&gt;
        &quot;lang&quot;:&quot;es-mx&quot;
    }
]
</code></pre>
<h1><a id="Comments_in_training_files_1237"></a>Comments in training files</h1>
<p>Comment must start from a new line and be prefixed with either <code>#</code> or <code>//</code></p>
<h1><a id="Long_lines_continuation_1240"></a>Long lines continuation</h1>
<p>Use backslash <code>\</code> to break long line. NOTE, white spaces on next line are ignored.</p>
<h1><a id="Unknown_word_marker_1243"></a>Unknown word marker</h1>
<p><strong><code>&lt;UNK&gt;</code></strong> is used in training sets to mark words that are not in the vocabulary of the training set.</p>
<h1><a id="Named_Entity_Recognition_1246"></a>Named Entity Recognition</h1>
<p>Can you imagine number of pizza types, toppings, crust etc. Well, and this is not the worst example. Now, if to put all combinations in utterances, training set can be easily few millions samples. Which is not good if you want to have <code>named entity recognition</code>. To solve this, you have to come up with the training set, where unknown words would be labled based on the context and not by the context and the value. Lets have a layer that would isolate P_TOPPING label. Note, this is a type, not a slot value.</p>
<pre><code>.define 
    @unk: &lt;UNK&gt;|&lt;UNK&gt; &lt;UNK&gt;|&lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt;
.user
    pizza with @unk{&amp;P_TOPPING} on top
    pizza with @unk{&amp;P_TOPPING} topping
</code></pre>
<p>Next lets have a slot assignment layer:</p>
<pre><code>.slist = topping_list
    ham
    onions
    mushrooms
    ...
.user
    // Assign slot t_topping with P_TOPPING value
    pizza with P_TOPPING{t_topping} on top
    .gate2
        // Check if history has a slot t_topping and it is present in the list of known toppings
        if hasattr( o, 't_topping' ):
            if o.t_topping not in g_topping_list:
                // Too bad, the topping is not known
                del o.t_topping 
            else:
                // Topping value has been validated
                pass
</code></pre>
<p>Third layer:</p>
<pre><code>.user
    ORDER_PIZZA: I would like to order pizza with ham on top
    ORDER_PIZZA: I would like to have a pizza with onions topping
    ...
</code></pre>
<p>User utterance: I want pizza with onions on top</p>
<pre><code>{
    &quot;t_utterance&quot;: &quot;I want pizza with onions on top&quot;,
    &quot;t_intent&quot; : ORDER_PIZZA,
    &quot;t_topping&quot;: &quot;onions&quot;
}
</code></pre>
<p>This approach is recommended to be used when you dont know all the values of the slot type or values are known, but they are too many. Training set must include utterances that create sufficient, high probability context to be sure that unknown word is something that we are looking for. We will not be discussing here whether this is good or bad way leaving it to developers, because it is task specific. The example above can be handled in one layer, if desired.</p>
<h1><a id="Expert_systems_support_1292"></a>Expert systems support</h1>
<p>The platform support a layer type, which goal is not related to NLU. You may decide to collect slots values and feed them to expert layer to infer additional information. Example: Doctor patient use case. Patient comes to a doctor and the assistent app asks a set of questions. Patients answers are collected as a slot values and as a prompt passed to expert system layer to make a diagnosys.</p>
<h1><a id="Recommendations_tips_and_tricks_1295"></a>Recommendations, tips and tricks</h1>
<ul>
<li>
<p>Before starting creating a <code>project</code> or <code>knowledge domain</code> important to remember:<br>
There are two ways to describe something. <strong><code>What it IS</code></strong> and <strong><code>what it IS NOT</code></strong>. Remember <strong>Hello</strong> example in this tutorial? Does not matter what you say, it will <code>always</code> produce <code>GREETING</code> intent! Why? Because the example does not have any alternative samples to tell apart Hello World from any other things user may say. Consider the example:</p>
<pre><code>.train
    INT_FLIGHT_INFO:show me flights to Seattle{t_dest}
    don't show me flights to Seattle
</code></pre>
<p>Second sample does not have an intent or slots to infere. This means that this statement will be <strong><code>just ignored</code></strong> and no inference will be made, <strong>if we wish</strong>. So, the training process will teach the model to remember the difference between these samples.</p>
</li>
<li>
<p>Do not use intent names that can be confused for words. I recommend using something like <code>INT_DO_SOMETHING</code>.</p>
</li>
<li>
<p>Name intents describing what to do next, rather then what already happened. While following train of though of the dialog, it is much easier.</p>
</li>
<li>
<p>Do not use slot types names that can be confused for words. I recommend using something like <code>PIZZA_KIND</code> or similar</p>
</li>
<li>
<p>Slot name template is <strong><code>t_&lt;name&gt;</code></strong> keeping in mind that <strong><code>t_intent</code></strong>, <strong><code>t_prev_intent</code></strong>, <strong><code>t_utt</code></strong> and <strong><code>t_prompt</code></strong> are reserved.</p>
</li>
<li>
<p>Slot inference. Consider two training sets:<br>
<code>Single layer project</code> which attempts not to use slot types isolation step:</p>
<pre><code>    .train
        INT_NAVIGATE:take me to (Los Angeles){t_dest} and to (New York){t_dest}
</code></pre>
<p>with inference for the sample above:</p>
<pre><code class="language-json">    {
        "<span class="hljs-attribute">t_intent</span>":<span class="hljs-value"><span class="hljs-string">"INT_NAVIGATE"</span></span>,
        "<span class="hljs-attribute">t_dest</span>":<span class="hljs-value">[<span class="hljs-string">"Los"</span>, <span class="hljs-string">"Angeles"</span>, <span class="hljs-string">"New"</span>, <span class="hljs-string">"York"</span>]
    </span>}
</code></pre>
<p>vs <code>Two layers project</code> which uses type definition layer and a separate slot value inference layer:</p>
<pre><code>    # Layer 1 - type training
    .train 
        take me to (Los Angeles){&amp;P_PLACE} and to (New York){&amp;P_PLACE}
</code></pre>
<pre><code>    # Layer 2 - intents and slots inference
    .train
        INT_NAVIGATE:take me to P_PLACE{t_dest} and to P_PLACE{t_dest}
</code></pre>
<p>with inference for the sample:</p>
<pre><code class="language-json">    {
        "<span class="hljs-attribute">t_intent</span>":<span class="hljs-value"><span class="hljs-string">"INT_NAVIGATE"</span></span>,
        "<span class="hljs-attribute">t_dest</span>":<span class="hljs-value">[<span class="hljs-string">"Los Angeles"</span>, <span class="hljs-string">"New York"</span>]
    </span>}
</code></pre>
<p>You can see the advantage of second approach, where names are correctly isolated.</p>
</li>
<li>
<p><a href="http://www.zcymatix.com"><code>zCymatix</code></a> platform <strong>does not</strong> provide <code>voice recognition services</code>. For web applications we recommend using <a href="https://cloud.google.com/speech/"><code>Google service</code></a>, since it is superior of other products available on the market today. See also available solutions for <a href="https://developer.android.com/reference/android/speech/SpeechRecognizer.html">Android</a> and <a href="https://developer.apple.com/documentation/speech">iOS</a>.</p>
</li>
</ul>
<h1><a id="Optional_configuration_parameters_1348"></a>Optional configuration parameters</h1>
<p><strong>NOTE</strong>! If the meaning of the parameters are not clear, keep the defaults or drop me a note.</p>
<ul>
<li>
<p>Depth of the model. By default, <code>1</code></p>
<pre><code>&quot;n_lstm&quot;:1
</code></pre>
</li>
<li>
<p>Bidirectional LSTM models. By default, <code>true</code>.</p>
<pre><code>&quot;bi_lstm&quot;:true
</code></pre>
<p>Example :</p>
<pre><code>I want ABC{t_pizza_type} pizza
I want ABC{t_pizza_topping} on top
</code></pre>
<p>Unless <code>bi_lstm</code> is enabled, model will not be able to tell that in first case <code>ABC</code> refers to a <code>pizza type</code> and in second, to <code>pizza toppings</code>. It is sort of look ahead. There is an alternative though - enable convolutional layer.</p>
</li>
<li>
<p>Training confidence level. By default, <code>0.9</code> - 90%. Level to consider inference reliable during training. If infered intent has lower probability, it will be replaced with <code>error_intent</code>, if it is set.</p>
<pre><code>&quot;train_confidence&quot;:0.9
</code></pre>
</li>
<li>
<p>Prediction confidence level. By default, <code>0.9</code> - 90%. Level to consider inference reliable during prediction. If infered intent has lower probability, it will be replaced with <code>error_intent</code>, if it is set.</p>
<pre><code>&quot;pred_confidence&quot;:0.9
</code></pre>
</li>
<li>
<p>Learning rate value. By default, <code>0.01</code>.</p>
<pre><code>&quot;lr&quot;:0.01
</code></pre>
</li>
<li>
<p>Minimum Learning rate value. By default, <code>0.001</code>.</p>
<pre><code>&quot;lr_min&quot;:0.001
</code></pre>
</li>
<li>
<p>Learning rate increase factor value. By default, <code>0.01</code>.</p>
<pre><code>&quot;lr_increase_factor&quot;:0.01
</code></pre>
</li>
<li>
<p>Learning rate reduce factor value. By default, <code>-0.2</code>.</p>
<pre><code>&quot;lr_reduce_factor&quot;:-0.2
</code></pre>
</li>
<li>
<p>Number of training epoches before reducing learning rate by <code>lr_reduce_factor</code>. By default, <code>3</code>.</p>
<pre><code>&quot;not_converge_max_epochs&quot;:3
</code></pre>
</li>
<li>
<p>To enable passing previous intent in the history as utterance prefix. By default, it is <code>true</code></p>
<pre><code>&quot;toth&quot;:false
</code></pre>
</li>
<li>
<p>Toth fallback mode . By default, it is <code>true</code>. If true, and the inference probability of the intent is lower than confidence level, <code>toth</code> mode will be turned off for this inference.</p>
<pre><code>&quot;toth_fallback_mode&quot;:true
</code></pre>
</li>
<li>
<p>A layer can be optionally included into the inference pipeline. When <code>accept_r_intents_only</code> is True , only  <code>R~</code> prefixed intent produced by one of the <strong>previous layers</strong> will enable this layer to be included in the inference. By default, is it <code>False</code>.  This is useful for expert system layers, where it should not be a part of collecting slots values, but rather when we need to process the whole collection of the slots.</p>
<pre><code>&quot;accept_r_intents_only&quot;:true
</code></pre>
</li>
<li>
<p>It is possible to change <code>vendor</code> name since you are the <code>vendor</code> of this project or knowledge domain</p>
<pre><code>&quot;vendor&quot;:&quot;zCymatix&quot;
</code></pre>
</li>
<li>
<p>To change version number of the training set define <code>version</code> parameter.</p>
<pre><code>&quot;version&quot;:&quot;0000.0000.0000&quot;
</code></pre>
</li>
<li>
<p>To include vendor name into the inferences. By default, it is <code>False</code></p>
<pre><code>&quot;include_vendor&quot;:false
</code></pre>
</li>
<li>
<p>To include version number into the inferences. By default, it is <code>False</code></p>
<pre><code>&quot;include_version&quot;:false
</code></pre>
</li>
<li>
<p>To include layer name into the inferences. By default, it is <code>False</code></p>
<pre><code>&quot;include_layer_name&quot;:false
</code></pre>
</li>
<li>
<p>To include intents into the inferences. By default, it is <code>True</code></p>
<pre><code>&quot;include_intents&quot;:true
</code></pre>
</li>
<li>
<p>To include prompt into the inferences. By default, it is <code>True</code></p>
<pre><code>&quot;include_prompts&quot;:true
</code></pre>
</li>
<li>
<p>To include utterance into the inferences. By default, it is <code>True</code></p>
<pre><code>&quot;include_utt&quot;:true
</code></pre>
</li>
<li>
<p>To keep last intent only in the inferences. By default, it is <code>True</code></p>
<pre><code>&quot;keep_last_intent&quot;:true
</code></pre>
</li>
<li>
<p>To keep last prompt only in the inferences. By default, it is <code>True</code></p>
<pre><code>&quot;keep_last_prompt&quot;:true
</code></pre>
</li>
<li>
<p>To keep last utterance only in the inferences. By default, it is <code>True</code></p>
<pre><code>&quot;keep_last_utterance&quot;:true
</code></pre>
</li>
<li>
<p>To convert the intent value to an utterance for the next layer in the inference pipeline. By default, it is <code>False</code>.</p>
<pre><code>&quot;intent_to_utterance&quot;:false
</code></pre>
<p>This is quite useful feature. Example: We want to interpret users loose answer that would be considered <code>yes</code> or <code>no</code>.</p>
<pre><code>.train
    INT_YES:I guess so|it is rather yes then no|...
</code></pre>
<p>If the intent was <code>INT_YES</code> it will become an utterance for next layer(!) reducing training set of this layer to deal only with <code>INT_YES</code> or <code>INT_NO</code><br>
Alternatively, prompt mechanism can be used to achieve the same result, however this feature flag saves additional typing. I will not suggest which one is better. It depends on the application.</p>
<pre><code>.train
    INT_YES:I guess so|it is rather yes then no|...
.prompt
    // Utterance for the next layer will be the intent itself taken 
    // from the current inference
    INT_YES: {.t_intent}
</code></pre>
<p>See <a href="#Prefix______657">Prefix .</a></p>
</li>
</ul>
<h1><a id="Advanced_configuration_parameters_1474"></a>Advanced configuration parameters</h1>
<p><strong>NOTE!</strong> If the meaning of the parameters are not clear, keep the defaults or drop me a note.</p>
<ul>
<li>
<p>To force backend to use GPUs for training. Default is CPU.</p>
<pre><code>&quot;hw&quot;:&quot;gpu&quot;
</code></pre>
</li>
<li>
<p>Accuracy metrics to be used for training. By default: <code>accuracy</code>, <code>loss</code> and <code>validation accuracy</code> are used.</p>
<pre><code>&quot;accuracy_metrics&quot;:[ &quot;acc&quot;, &quot;loss&quot;, &quot;val_acc&quot; ]
</code></pre>
</li>
<li>
<p>Accuracy metrics to stop training early. Defaults in the same order: <code>accuracy = 1.0</code>, <code>accuracy_loss = 0.01</code>, <code>validatoion_accuracy = 1.0</code>, <code>validation_loss = 0.01</code></p>
<pre><code>&quot;stop_accuracy_metrics&quot;:[ 1.0, 0.01, 1.0, 0.01 ]
</code></pre>
</li>
<li>
<p>The training model by default, returns sequences of labels. However, in case when you have a layer which deals with only intents without any slots it makes sense to change it to disable the sequence, thus to return only final result. It leads to faster training times.</p>
<pre><code>&quot;return_sequences&quot;:true
</code></pre>
<p>Example:</p>
<pre><code>.train
    INT_YES: sure|yes|of course|I would say so|...
    INT_NO: no|nope|I don't think so|negative|no way|...
</code></pre>
</li>
<li>
<p>Number of epochs to train. By default, it is <code>100000</code></p>
<pre><code>&quot;n_epochs&quot;:100000
</code></pre>
</li>
<li>
<p>Embedding vector size. By default, it is <code>50</code></p>
<pre><code>&quot;emb_dimension&quot;:50
</code></pre>
</li>
<li>
<p>Number of hidden units. By default, it is <code>100</code></p>
<pre><code>&quot;n_hidden&quot;:100
</code></pre>
</li>
<li>
<p>Dropout coefficient for feature vector. By default, it is <code>0.1</code></p>
<pre><code>&quot;dropout_W&quot;:0.1
</code></pre>
</li>
<li>
<p>Dropout coefficient for hidden units. By default, it is <code>0.1</code></p>
<pre><code>&quot;dropout_U&quot;:0.1
</code></pre>
</li>
<li>
<p>Optimizer name. By default, <code>Adam</code></p>
<pre><code>&quot;optimizer&quot;:&quot;Adam&quot;
</code></pre>
</li>
<li>
<p>List of optimizers and their parameters. Defaults are listed below.</p>
<pre><code>&quot;optimizers&quot;:[
    'SGD(lr = 0.0001, decay = 0.000001, momentum = 0.9, nesterov = True)',
    'Adam(lr = 0.01, decay = 0.000001, beta_1 = 0.9, beta_2 = 0.999)',
    'Nadam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, schedule_decay = 0.000001)',
    'RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay = 0.0)',
    'Adagrad(lr = 0.01, epsilon = 1e-08, decay = 0.0)',
    'Adadelta(lr = 1.0, rho = 0.95, epsilon = 1e-08, decay = 0.0)',
    'Adamax(lr = 0.002, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0)'    
]
</code></pre>
</li>
<li>
<p>Use convolutional layer. By default, <code>false</code>. See the description <a href="https://keras.io/layers/convolutional/#conv1d">here</a></p>
<pre><code>&quot;conv&quot;:false
</code></pre>
</li>
<li>
<p>Convolutional layer outputs. By default, <code>128</code>. See the description <a href="https://keras.io/layers/convolutional/#conv1d">here</a></p>
<pre><code>&quot;conv_outputs&quot;:128
</code></pre>
</li>
<li>
<p>Convolutional layer kernel size. By default, <code>5</code>. See the description <a href="https://keras.io/layers/convolutional/#conv1d">here</a></p>
<pre><code>&quot;conv_kernel_size &quot;:128
</code></pre>
</li>
<li>
<p>Convolutional layer activation function. By default, <code>relu</code>. See the description <a href="https://keras.io/layers/convolutional/#conv1d">here</a></p>
<pre><code>&quot;conv_activation &quot;:&quot;relu&quot;
</code></pre>
</li>
<li>
<p>Convolutional layer padding method. By default, <code>same</code>. See the description <a href="https://keras.io/layers/convolutional/#conv1d">here</a></p>
<pre><code>&quot;conv_padding &quot;:&quot;same&quot;
</code></pre>
</li>
<li>
<p>Dropout layer value. By default, <code>0.0</code>.</p>
<pre><code>&quot;dropout_layer_value &quot;:0.0
</code></pre>
</li>
<li>
<p>Include signle words into training set. By default, <code>false</code>. If true, all single words are added to the training set without any labels.</p>
<pre><code>&quot;include_single_words&quot;:false
</code></pre>
</li>
<li>
<p>Include intent names into training set. By default, <code>false</code>. If true, all intents are added to the training set without any labels.</p>
<pre><code>&quot;include_intent_words&quot;:false
</code></pre>
</li>
<li>
<p>Error intent. By default, ``. If set, this is the intent to be used if inference probability did not reach confidence level.</p>
<pre><code>&quot;error_intent&quot;:&quot;&quot;
</code></pre>
</li>
</ul>
</body></html>
